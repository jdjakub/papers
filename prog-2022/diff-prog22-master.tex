\documentclass[english,submission]{programming}
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL diff/old-prog22-master.tex   Tue May 31 19:19:16 2022
%DIF ADD diff/new-prog22-master.tex   Mon Jun  6 21:56:24 2022

%\citestyle{acmauthoryear}
%\markboth{}{}

% Class scrartcl Warning: seems someone has broken package `auxhook'.
% Usually this happens, if `auxhook' is loaded or used implicitly or explicitly
% by patching \document or via etoolbox command \AtEndPreamble. Trying an
% emergency workaround. You can avoid this warning adding:
\usepackage{auxhook}
% before \begin{document} on input line 6.
\usepackage{changepage} % For the single-page summary table PDF insert.
\usepackage{pdfpages}
\usepackage{pifont} % For checkmark / cross symbols for Appendix table :) %DIF > 
 %DIF > 
% Thanks https://tex.stackexchange.com/a/32687 %DIF > 
\NewDocumentCommand{\rot}{O{45} O{1em} m}{\makebox[#2][l]{\rotatebox{#1}{#3}}}% %DIF > 
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFadd}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF LISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_UNDERLINE %DIF PREAMBLE
  moredelim=[il][\color{red}\sout]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\uwave]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}

\paperdetails{perspective=art, area={Programming systems}}

\title{Technical Dimensions of Programming Systems}

\author{Joel Jakubovic}
\affiliation{
University of Kent, Canterbury, UK
\email{jdj9@kent.ac.uk}
}
\author{Jonathan Edwards}
\affiliation{\email{jonathanmedwards@gmail.com}}
\author{Tomas Petricek}
\affiliation{
University of Kent, Canterbury, UK
\email{T.Petricek@kent.ac.uk}
}

\keywords{Programming Systems, Dimensions, Design, Framework, Analysis}

% Please go to https://dl.acm.org/ccs/ccs.cfm and generate your Classification
% System [view CCS TeX Code] stanz and copy _all of it_ to this place.
%% From HERE
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10011007.10011006.10011066.10011069</concept_id>
       <concept_desc>Software and its engineering~Integrated and visual development environments</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003121.10003129</concept_id>
       <concept_desc>Human-centered computing~Interactive systems and tools</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003121.10003122</concept_id>
       <concept_desc>Human-centered computing~HCI design and evaluation methods</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}
\ccsdesc[500]{Software and its engineering~Integrated and visual development environments}
\ccsdesc[300]{Human-centered computing~Interactive systems and tools}
\ccsdesc[300]{Human-centered computing~HCI design and evaluation methods}

\maketitle

\begin{abstract}
  \DIFdelbegin \DIFdel{Many programming systems go beyond programming languages. Programming }\DIFdelend \DIFaddbegin \emph{\DIFadd{Context.}} \DIFadd{Programming requires much more than just writing code in a programming language. It }\DIFaddend is usually done in the context of a stateful environment, \DIFdelbegin \DIFdel{beyond just writing code, }\DIFdelend by interacting with a system through a graphical user interface. \DIFdelbegin \DIFdel{Much research effort focuses on building programming systems that are easier to use, accessible to non-experts, moldable and/or powerful, but such efforts are often disconnected. They are informal, guided by the personal vision of the authors and thus are only evaluable and comparable on the basis of individual experience using them. They fail to }\DIFdelend \DIFaddbegin \DIFadd{Yet, this wide space of possibilities lacks a common structure for navigation. Work on programming systems fails to }\DIFaddend form a coherent body of research, \DIFdelbegin \DIFdel{since it is unclear how to build }\DIFdelend \DIFaddbegin \DIFadd{making it hard to improve }\DIFaddend on past work \DIFdelbegin \DIFdel{. In the research world}\DIFdelend \DIFaddbegin \DIFadd{and advance the state of the art.
}

  \emph{\DIFadd{Inquiry.}} \DIFadd{In computer science}\DIFaddend , much has been said and done \DIFdelbegin \DIFdel{that allows }\DIFdelend \DIFaddbegin \DIFadd{to allow }\DIFaddend comparison of \emph{programming languages}, yet no similar theory exists for \emph{programming systems\DIFdelbegin %DIFDELCMD < \MBLOCKRIGHTBRACE%%%
\DIFdelend ;\DIFaddbegin } \DIFaddend we believe that programming systems deserve a theory too. 
\DIFdelbegin \DIFdel{We examine some influential past programming systems and review their stated design principles, technical capabilities, and styles of user interaction. We propose }\DIFdelend \DIFaddbegin 

  \emph{\DIFadd{Approach.}} \DIFadd{We present }\DIFaddend a framework of \emph{technical dimensions} which capture the underlying \DIFdelbegin \DIFdel{system characteristics }\DIFdelend \DIFaddbegin \DIFadd{characteristics of programming systems }\DIFaddend and provide a means for conceptualizing and comparing \DIFdelbegin \DIFdel{programming systems. Since these characteristics may be compared or advanced independently, it should be easier }\DIFdelend \DIFaddbegin \DIFadd{them. 
}

  \emph{\DIFadd{Knowledge.}} \DIFadd{We identify technical dimensions by examining past influential programming systems and reviewing their design principles, technical capabilities, and styles of user interaction. Technical dimensions capture characteristics that may be studied, compared and advanced independently. This makes it possible }\DIFaddend to talk about programming systems in a way that can be shared and constructively debated rather than relying solely on personal impressions.
   \DIFaddbegin 

  \emph{\DIFadd{Grounding.}} \DIFadd{Our framework is derived using a qualitative analysis of past programming systems. We outline two concrete ways of using our framework. First, we show how it can analyze a recently developed novel programming system. Then, we use it to identify an interesting unexplored point in the design space of programming systems. 
}

  \emph{\DIFadd{Importance.}} \DIFadd{Much research effort focuses on building programming systems that are easier to use, accessible to non-experts, moldable and/or powerful, but such efforts are disconnected. They are informal, guided by the personal vision of the authors and thus are only evaluable and comparable on the basis of individual experience using them. }\DIFaddend By providing foundations for more systematic research\DIFdelbegin \DIFdel{in this area}\DIFdelend , we can help \DIFdelbegin \DIFdel{the designers of future programming systems }\DIFdelend \DIFaddbegin \DIFadd{programming systems researchers }\DIFaddend to stand, at last, on the shoulders of giants.

  NOTE TO REVIEWERS: The main contribution of the paper is a comprehensive survey of \DIFdelbegin \DIFdel{21 }\DIFdelend \DIFaddbegin \DIFadd{22 }\DIFaddend design dimensions of programming systems. Each one comes with detailed discussion, including known uses, to properly motivate it. Regrettably, we only have space for a small number of these dimensions in the main paper body. To give a broader picture of what we are contributing, we invite the reader to explore \DIFdelbegin \DIFdel{the Appendix}\DIFdelend \DIFaddbegin \DIFadd{Appendix\ \ref{dimensions-catalogue} }\DIFaddend for dimensions that suit their interest.
\end{abstract}

%\thispagestyle{empty}

\newcommand{\joel}[1]{}
\newcommand{\note}[1]{}
\newcommand{\tp}[1]{}
\newcommand{\mybox}[1]{\noindent\fbox{\parbox{\textwidth}{#1}}}
\providecommand{\tightlist}{}% Don't want Pandoc's tight lists
%\newcommand{\hypertarget}[1]{}

\begin{quote}
A systematic presentation removes ideas from the ground that made them
grow and arranges them in an artificial pattern.

--- Paul Feyerabend, \emph{The Tyranny of Science}, Polity Press (2011)
\end{quote}

\begin{quote}
Irony is said to allow the artist to continue his creative production
while immersed in a sociocultural context of which he is critical.

--- Emmanuel Petit, \emph{Irony or, the Self-Critical Opacity of
Postmodernist Architecture}, Yale (2013)
\end{quote}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Many forms of software have been developed to enable programming. The
classic form consists of a \emph{programming language}, a text editor to
enter source code, and a compiler to turn it into an executable program.
Instances of this form are differentiated by the syntax and semantics of
the language, along with the implementation techniques in the compiler
or runtime environment. Since the advent of graphical user interfaces
(GUIs), programming languages can be found embedded within graphical
environments that increasingly define how programmers work with the
\DIFdelbegin \DIFdel{language (}\DIFdelend \DIFaddbegin \DIFadd{language---for instance, }\DIFaddend by directly supporting debugging or
refactoring\DIFdelbegin \DIFdel{, for
instance. ) }\DIFdelend \DIFaddbegin \DIFadd{. }\DIFaddend Beyond this, the rise of GUIs also permits diverse visual
forms of programming, including visual languages and GUI-based end-user
programming tools. This paper \DIFdelbegin \DIFdel{relies on, and encourages, }\DIFdelend \DIFaddbegin \DIFadd{advocates }\DIFaddend a shift of attention from
\emph{programming languages} to the more general notion of ``software
that enables programming''---in other words, \emph{programming systems}.

A \emph{programming system} may include tools, protocols, notations,
\DIFaddbegin \DIFadd{interfaces, }\DIFaddend and languages. It is a software artifact that makes it
possible to construct programs, debug them, and turn them into
operational, maintained, and evolvable artifacts running on appropriate
hardware. This notion covers classic programming languages together with
their editors, debuggers, compilers, and other tools. Yet it is
intentionally broad enough to accommodate image-based programming
environments like Smalltalk, operating systems like UNIX, and hypermedia
authoring systems like Hypercard, in addition to various other examples
we will mention.

\hypertarget{what-is-the-problem}{%
\subsection{What is the problem?}\label{what-is-the-problem}}

There is a growing interest in broader forms of \emph{programming
systems}, both in the programming research community and in industry. On
the one hand, researchers are \DIFdelbegin \DIFdel{increasingly }\DIFdelend studying topics such as \emph{programming
experience} and \emph{live programming} that require considering not
just the \emph{language}, but further aspects of a given system. On the
other hand, commercial companies are building new programming
environments like Replit\DIFdelbegin \footnote{\DIFdel{https://replit.com/}} %DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{~\mbox{%DIFAUXCMD
\cite{ReplitWeb} }\hspace{0pt}%DIFAUXCMD
}\DIFaddend or low-code \DIFdelbegin \DIFdel{programming }\DIFdelend tools like
Dark\DIFdelbegin \footnote{\DIFdel{https://darklang.com/}} %DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdel{and Glide.}\footnote{\DIFdel{https://www.glideapps.com/}} %DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{~\mbox{%DIFAUXCMD
\cite{DarkWeb} }\hspace{0pt}%DIFAUXCMD
and Glide~\mbox{%DIFAUXCMD
\cite{GlideWeb}}\hspace{0pt}%DIFAUXCMD
. }\DIFaddend Yet, such topics remain
at the sidelines of mainstream programming research. While
\emph{programming languages} are a well-established concept, analysed
and compared in a common vocabulary, no similar foundation exists for
the wider range of \emph{programming systems}.

The academic research on programming suffers from this lack of common
vocabulary. While we \DIFdelbegin \DIFdel{can }\DIFdelend \DIFaddbegin \DIFadd{may }\DIFaddend thoroughly assess programming \DIFdelbegin \DIFdel{languages}\DIFdelend \DIFaddbegin \emph{\DIFadd{languages}}\DIFaddend ,
as soon as we add interaction or graphics into the picture, we often get
stuck on how the resulting system is vaguely ``\DIFdelbegin \DIFdel{cool'' or
``}\DIFdelend interesting''. Moreover,
when designing new systems, inspiration is often drawn from the same few
standalone sources of ideas. These might be influential past systems
like Smalltalk, programmable end-user applications like spreadsheets, or
motivational illustrations by thinkers like Victor~\cite{BretVictor}.

Instead of forming a solid body of work, the ideas that emerge are
difficult to relate to each other. \DIFdelbegin \DIFdel{Similarly, the }\DIFdelend \DIFaddbegin \DIFadd{The }\DIFaddend research methods used to study
programming systems lack the \DIFdelbegin \DIFdel{more }\DIFdelend rigorous structure of programming language
research methods. They tend to rely on singleton examples, which
demonstrate the author's ideas, but are inadequate methods for comparing
new ideas with the work of others. This makes it hard to build on top
and thereby advance the state of the art.

Studying \emph{programming systems} is not merely about taking a
programming language and looking at the tools that surround it. It
presents a \emph{paradigm shift} to a perspective that is, at least
partly, \emph{incommensurable} with that of languages. When studying
programming languages, everything that matters is in the program code;
when studying programming systems, everything that matters is in the
\emph{interaction} between the programmer and the system. As documented
by Gabriel \cite{PLrev}, looking at a \emph{system} from a
\emph{language} perspective makes it impossible to think about concepts
that arise from interaction with a system, but are not reflected in the
language. Thus, we must proceed with some caution. As we will see, when
we talk about Lisp as a programming system, we mean something very
different from a parenthesis-heavy programming language!

\hypertarget{contributions}{%
\subsection{Contributions}\label{contributions}}

We propose a \DIFdelbegin \DIFdel{new }\DIFdelend common language as an initial \DIFdelbegin \DIFdel{, }\emph{\DIFdel{tentative}} %DIFAUXCMD
\DIFdel{step towards }\DIFdelend \DIFaddbegin \DIFadd{step towards a }\DIFaddend more
progressive research on programming systems. Our set of \DIFdelbegin \DIFdel{``Technical Dimensions for Programming Systems'' }\DIFdelend \DIFaddbegin \emph{\DIFadd{technical
dimensions}} \DIFaddend seeks to break down the holistic view of systems along
various specific ``axes''\DIFdelbegin \DIFdel{inspired by the
approach of the }\emph{\DIFdel{Cognitive~Dimensions of~Notation}}%DIFAUXCMD
\DIFdel{~\mbox{%DIFAUXCMD
\cite{CogDims}}\hspace{0pt}%DIFAUXCMD
.
While not strictly quantitative, we have designed them to be narrow
enough to be comparable, so that we may say one system has more or less
of a property than another. Generally, we see the various possibilities
as tradeoffs and are reluctant to assign them }\DIFdelend \DIFaddbegin \DIFadd{. The dimensions identify a range of possible
design choices, characterized by two extreme points in the design space.
They are not quantitative, but they allow comparison by locating systems
on a common axis. We do not intend for the extreme points to represent
}\DIFaddend ``good'' or ``bad'' \DIFdelbegin \DIFdel{status. If the framework is to be useful, then it must encourage some
sort of rough consensus on how to apply it}\DIFdelend \DIFaddbegin \DIFadd{designs}\DIFaddend ; we expect \DIFdelbegin \DIFdel{it will be more
helpful to agree }\DIFdelend \DIFaddbegin \DIFadd{any position to be a result of
design trade-offs. At this stage we encourage agreement }\DIFaddend on descriptions
of systems first, \DIFdelbegin \DIFdel{and settle }\DIFdelend \DIFaddbegin \DIFadd{in order to settle any }\DIFaddend normative judgements later.

The set of dimensions can be understood as a map of the design space of
programming systems (Figure~\ref{fig:tech-dims-diagram}). Past and
present systems will serve as landmarks, and with enough of them,
unexplored or overlooked possibilities will reveal themselves. So far,
the field has not been able to establish a virtuous cycle of feedback;
it is hard for practitioners to situate their work in the context of
others' so that subsequent work can improve on it. Our aim is to provide
foundations for the study of programming systems that would allow such
development.

\DIFaddbegin \DIFadd{This paper is intended as a reference on the current state of the
technical dimensions framework and it is meant to be }\emph{\DIFadd{used}} \DIFadd{rather
than }\emph{\DIFadd{read}}\DIFadd{. We present the dimensions in detail, but encourage the
reader to skim through the details on the first read. Subsequently, we
suggest revisiting dimensions which seem relevant to a concrete system
known to the reader. The main contributions of this paper are organized
as follows:
}

\DIFaddend \begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \DIFaddbegin \DIFadd{In Section~\ref{programming-systems}, we characterize what a
  programming system is and review landmark programming systems of the
  past that are used as examples throughout this paper, as well as to
  delineate our notion of a programming system.
}\item
  \DIFaddend We present the \DIFaddbegin \DIFadd{technical }\DIFaddend dimensions in detail, organised into related
  clusters: \emph{interaction}, \emph{notation}, \emph{conceptual
  structure}, \emph{customizability}, \emph{\DIFdelbegin \DIFdel{automation}\DIFdelend \DIFaddbegin \DIFadd{complexity}\DIFaddend }, \emph{errors},
  and \emph{adoptability}. \DIFdelbegin %DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\DIFdel{We define these dimensions by reference to landmark programming
  systems of the past, and discuss any relationships between them}\DIFdelend \DIFaddbegin \DIFadd{For each dimension, we give examples that
  illustrate a number of values along the axis identified by the
  dimension. Of these, only }\emph{\DIFadd{customizability}} \DIFadd{fits in the main body
  of the paper; the rest reside in Appendix~\ref{dimensions-catalogue}}\DIFaddend .
\item
  \DIFdelbegin \DIFdel{We demonstrate the salience of these dimensions by applying them to example systems from both the past and present.
We situate some
  experimental systems as explorations at the frontier of certain
  dimensions.
}\DIFdelend \DIFaddbegin \DIFadd{In Section~\ref{discussion}, we sketch two ways of using the technical
  dimensions framework. In Section~\ref{evaluating-programming-systems},
  we use it to evaluate a recent interesting programming system; in
  Section~\ref{exploring-the-design-space}, we use it to identify an
  unexplored point in the design space and envision a potential novel
  programming system.
}\DIFaddend \end{enumerate}

\DIFaddbegin \begin{figure}
  \centering
  \includegraphics[width=0.6\linewidth]{plot-figure0.pdf}
  \caption{\DIFaddFL{One 2-dimensional slice of the space of possible systems, to be examined in more detail in Section\ \ref{exploring-the-design-space}.}\label{fig:tech-dims-diagram}}
\end{figure}

\DIFaddend \hypertarget{related-work}{%
\section{Related work}\label{related-work}}

While we do have new ideas to propose, part of our contribution is
integrating a wide range of \emph{existing} concepts under a common
umbrella. This work is spread out across different domains, but each
part connects to programming systems or focuses on a specific
characteristic they may have.

\DIFdelbegin %DIFDELCMD < \hypertarget{which-systems-are-we-talking-about}{%
%DIFDELCMD < \subsection{Which ``systems'' are we talking
%DIFDELCMD < about?}\label{which-systems-are-we-talking-about}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{From languages to systems.}}
\DIFaddend 

\DIFdelbegin \DIFdel{The programming systems that shape our framework come from a
few
recognisable clusters:
}\DIFdelend \DIFaddbegin \DIFadd{Our approach lies between a narrow focus on programming languages and a
broad focus on programming as a socio-political and cultural subject.
Our concept of a programming system is technical in scope, although we
acknowledge the technical side often has important social implications
as in the case of the ``Adoptability'' dimension
(Section~\ref{adoptability}). This contrasts with the more
socio-political focus found in Tchernavskij \mbox{%DIFAUXCMD
\cite{TcherDiss} }\hspace{0pt}%DIFAUXCMD
or in
software studies \mbox{%DIFAUXCMD
\cite{SwStudies}}\hspace{0pt}%DIFAUXCMD
. It overlaps with Kell's
conceptualization of UNIX, Smalltalk, and Operating Systems
generally~\mbox{%DIFAUXCMD
\cite{KellOS}}\hspace{0pt}%DIFAUXCMD
, and we have ensured that UNIX has a place in
our framework.
}\DIFaddend 

\DIFdelbegin %DIFDELCMD < \begin{itemize}
\begin{itemize}%DIFAUXCMD
%DIFDELCMD < \tightlist
%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\DIFdel{``Platforms'' supporting arbitrary software ecosystems: UNIX, Lisp,
  Smalltalk, the Web
}%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\DIFdel{``Applications'' targeted to a specific domain: spreadsheets
}%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\DIFdel{Mixed aspects of platform and application: HyperCard, Boxer, Flash,
  and programming language workflows
}
\end{itemize}%DIFAUXCMD
%DIFDELCMD < \end{itemize}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{The distinction between more narrow }\emph{\DIFadd{programming languages}} \DIFadd{and
broader }\emph{\DIFadd{programming systems}} \DIFadd{is more subtle. }\DIFaddend Richard Gabriel noted
\DIFdelbegin \DIFdel{a ``paradigm shift '' \mbox{%DIFAUXCMD
\cite{PLrev} }\hspace{0pt}%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{an invisible paradigm shift }\DIFaddend from the study of \DIFdelbegin \DIFdel{systems }\DIFdelend \DIFaddbegin \DIFadd{``systems'' }\DIFaddend to the study
of \DIFdelbegin \DIFdel{languages }\DIFdelend \DIFaddbegin \DIFadd{``languages'' }\DIFaddend in computer science \DIFdelbegin \DIFdel{, which }\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{PLrev}}\hspace{0pt}%DIFAUXCMD
, and this observation
}\DIFaddend informs our distinction here. One consequence of the change is that a
\emph{language} is often formally specified apart from any specific
implementations, while \emph{systems} resist formal specification and
are often \emph{defined by} an implementation. We \DIFdelbegin \DIFdel{do, however, intend to
}\DIFdelend recognize programming
language implementations as a \emph{small region} of the space of
possible systems\DIFdelbegin \DIFdel{(Figure~\ref{fig:tech-dims-diagram})}\DIFdelend \DIFaddbegin \DIFadd{, at least as far as interaction and notations might go}\DIFaddend .
Hence we refer to the \emph{interactive programming system} aspects of
languages, such as text editing and command-line workflow.

\DIFdelbegin %DIFDELCMD < \begin{figure}
%DIFDELCMD <   \centering
%DIFDELCMD <   \includegraphics[width=0.5\linewidth]{tech-dims-diagram.png}
%DIFDELCMD <   %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\DIFdelFL{A speculative sketch of one 2-dimensional slice of the space of possible systems.}%DIFDELCMD < \label{fig:tech-dims-diagram}%%%
}
%DIFAUXCMD
%DIFDELCMD < \end{figure}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Programming systems research.}}
\DIFaddend 

\DIFdelbegin \DIFdel{Our ``system'' concept is mostly technical in scope, with occasional
excursions as in ``Adoptability'' (Section~\ref{adoptability}). This
contrasts with the more socio-political focus found in Tchernavskij
\mbox{%DIFAUXCMD
\cite{TcherDiss}}\hspace{0pt}%DIFAUXCMD
. It overlaps with Kell's conceptualization of UNIX,
Smalltalk, and Operating Systems generally~\mbox{%DIFAUXCMD
\cite{KellOS}}\hspace{0pt}%DIFAUXCMD
, and we have
ensured that UNIX has a place in our framework.
}%DIFDELCMD < 

%DIFDELCMD < \hypertarget{industry-and-research-interest-in-programming-systems}{%
%DIFDELCMD < \subsection{Industry and research interest in programming
%DIFDELCMD < systems}\label{industry-and-research-interest-in-programming-systems}}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend There is renewed interest in programming systems in both industry and
research\DIFdelbegin \DIFdel{. In industry we see}\DIFdelend \DIFaddbegin \DIFadd{, but the holistic programming systems view is more often
adopted in work on non-traditional programming tools}\DIFaddend :

\begin{itemize}
\tightlist
\item
  Computational notebooks such as Jupyter \DIFdelbegin \footnote{\DIFdel{https://jupyter.org/}}
  %DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdel{that make data analysis more amenable to scientists }\DIFdelend \DIFaddbegin \DIFadd{simplify data analysis }\DIFaddend by
  combining code snippets \DIFdelbegin \DIFdel{and their numerical or graphical outputin a convenient
  document format. }\DIFdelend \DIFaddbegin \DIFadd{with text and visual output. They are backed
  by stateful ``kernels'' and used interactively.
}\DIFaddend \item
  ``Low code'' end-user programming systems \DIFdelbegin \DIFdel{that present a simplified
  GUIfor developing applications}\DIFdelend \DIFaddbegin \DIFadd{allow application
  development (mostly) through a GUI}\DIFaddend . One example is Coda
  \DIFdelbegin \DIFdel{,}\footnote{\DIFdel{https://coda.io/welcome}}
  %DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{CodaWeb}}\hspace{0pt}%DIFAUXCMD
, }\DIFaddend which combines tables, formulas, and scripts to enable
  non-technical people to build ``applications as \DIFdelbegin \DIFdel{a document}\DIFdelend \DIFaddbegin \DIFadd{documents}\DIFaddend ''.
\item
  \DIFdelbegin \DIFdel{Specialized programming systems that augment a specific domain. For
  example }\DIFdelend \DIFaddbegin \DIFadd{Domain-specific programming systems such as }\DIFaddend Dark, which \DIFdelbegin \DIFdel{creates cloud API services with }\DIFdelend \DIFaddbegin \DIFadd{claims }\DIFaddend a
  ``holistic'' programming experience \DIFdelbegin \DIFdel{including a languageand }\DIFdelend \DIFaddbegin \DIFadd{for cloud API services. This
  includes a language, a }\DIFaddend direct manipulation editor\DIFdelbegin \DIFdel{with }\DIFdelend \DIFaddbegin \DIFadd{, and
  }\DIFaddend near-instantaneous building and deployment.
\item
  Even for general purpose programming with conventional tools, systems
  like Replit have demonstrated the benefits of integrating all needed
  languages, tools, and user interfaces into a seamless experience\DIFdelbegin \DIFdel{available from a browserwith }\DIFdelend \DIFaddbegin \DIFadd{,
  available from the browser, that requires }\DIFaddend no setup.
\end{itemize}

\DIFdelbegin \DIFdel{In research , there are an increasing number of explorations of the
possibilities of full programming systems:
}\DIFdelend \DIFaddbegin \DIFadd{Research that follows the programming systems perspective can be found
in a number of research venues. Those include Human-Computer Interaction
conferences such as }\href{https://uist.acm.org/}{\DIFadd{UIST}}\footnote{\DIFadd{ACM
  Symposium on User Interface Software and Technology}} \DIFadd{and
}\href{https://conferences.computer.org/VLHCC/}{\DIFadd{VL/HCC}}\footnote{\DIFadd{IEEE
  Symposium on Visual Languages and Human-Centric Computing}}\DIFadd{. However,
work in those often emphasizes the user experience over technical
description. Programming systems are often presented in workshops such
as }\href{https://liveprog.org/}{\DIFadd{LIVE}} \DIFadd{and
}\href{https://2021.programming-conference.org/home/px-2021}{\DIFadd{PX}}\footnote{\DIFadd{Programming
  eXperience}}\DIFadd{. However, work in those venues is often limited to the
authors' individual perspectives and suffers from the aforementioned
difficulty of comparing to other systems.
}\DIFaddend 

\DIFdelbegin %DIFDELCMD < \begin{itemize}
%DIFDELCMD < \tightlist
%DIFDELCMD < \item
%DIFDELCMD <   %%%
\DIFdelend \DIFaddbegin \DIFadd{Concrete examples of systems appear throughout the paper. Recent systems
which motivated some of our dimensions include }\DIFaddend Subtext \cite{Subtext},
which combines code with its live execution in a single editable
representation\DIFdelbegin \DIFdel{.
}%DIFDELCMD < \item
%DIFDELCMD <   %%%
\DIFdelend \DIFaddbegin \DIFadd{; }\DIFaddend Sketch-n-sketch \cite{SnS}, which can synthesize code by
direct manipulation of its outputs\DIFdelbegin \DIFdel{.
}%DIFDELCMD < \item
%DIFDELCMD <   %%%
\DIFdelend \DIFaddbegin \DIFadd{; }\DIFaddend Hazel \cite{Hazel}, a live
functional programming environment \DIFdelbegin \DIFdel{featuring typed holes which }\DIFdelend \DIFaddbegin \DIFadd{with typed holes to }\DIFaddend enable execution
of incomplete or \DIFdelbegin \DIFdel{type-erroneous programs.
}%DIFDELCMD < \end{itemize}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{ill-typed programs; and Webstrates \mbox{%DIFAUXCMD
\cite{Webstrates}}\hspace{0pt}%DIFAUXCMD
,
which extends Web pages with real-time sharing of state.
}\DIFaddend 

\DIFdelbegin \DIFdel{Several research venues investigate programming systems:
}\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Already-known characteristics.}}
\DIFaddend 

\DIFdelbegin %DIFDELCMD < \begin{itemize}
\begin{itemize}%DIFAUXCMD
%DIFDELCMD < \tightlist
%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\href{https://uist.acm.org/}{\DIFdel{UIST}} %DIFAUXCMD
\DIFdel{(ACM Symposium on User Interface
  Software and Technology)
}%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\href{https://conferences.computer.org/VLHCC/}{\DIFdel{VL/HCC}} %DIFAUXCMD
\DIFdel{(IEEE Symposium
  on Visual Languages and Human-Centric Computing)
}%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\DIFdel{The }\href{https://liveprog.org/}{\DIFdel{LIVE programming}} %DIFAUXCMD
\DIFdel{workshop at SPLASH
}%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\DIFdel{The }\href{https://2021.programming-conference.org/home/px-2021}{\DIFdel{PX}}
  %DIFAUXCMD
\DIFdel{(Programming eXperience) workshop at \(\langle\)Programming\(\rangle\)
}
\end{itemize}%DIFAUXCMD
%DIFDELCMD < \end{itemize}
%DIFDELCMD < 

%DIFDELCMD < \hypertarget{characteristics-already-identified-elsewhere}{%
%DIFDELCMD < \subsection{Characteristics already identified
%DIFDELCMD < elsewhere}\label{characteristics-already-identified-elsewhere}}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend There are several existing projects identifying characteristics of
programming systems. Some \DIFdelbegin \DIFdel{of these }\DIFdelend revolve around a single one, such as levels of
liveness \cite{Liveness}, or plurality and communicativity
\cite{KellComm}. Others propose \DIFdelbegin \DIFdel{, as we do here, }\DIFdelend an entire collection\DIFdelbegin \DIFdel{:
}%DIFDELCMD < 

%DIFDELCMD < \begin{itemize}
%DIFDELCMD < \tightlist
%DIFDELCMD < \item
%DIFDELCMD <   %%%
\DIFdelend \DIFaddbegin \DIFadd{. }\DIFaddend \emph{Memory
\DIFdelbegin \DIFdel{~}\DIFdelend Models of \DIFdelbegin \DIFdel{~}\DIFdelend Programming \DIFdelbegin \DIFdel{~}\DIFdelend Languages}~\cite{MemMod} identifies the
``everything is an X'' metaphors underlying many programming languages\DIFdelbegin \DIFdel{.
}%DIFDELCMD < \item
%DIFDELCMD <   %%%
\DIFdel{The }\DIFdelend \DIFaddbegin \DIFadd{;
the }\DIFaddend \emph{Design \DIFdelbegin \DIFdel{~}\DIFdelend Principles of \DIFdelbegin \DIFdel{~}\DIFdelend Smalltalk}~\cite{STdesign} documents the
philosophical goals and dicta used in the design of Smalltalk\DIFdelbegin \DIFdel{.
}%DIFDELCMD < \item
%DIFDELCMD <   %%%
\DIFdel{The }\DIFdelend \DIFaddbegin \DIFadd{; the
}\DIFaddend ``Gang of Four'' \emph{Design Patterns}~\cite{DesPats} \DIFdelbegin \DIFdel{names and
  catalogues
specific tactics within the }\DIFdelend \DIFaddbegin \DIFadd{catalogues
specific implementation tactics; and the }\DIFaddend \emph{\DIFdelbegin \DIFdel{codebases}\DIFdelend \DIFaddbegin \DIFadd{Cognitive Dimensions of
Notation}\DIFaddend }\DIFdelbegin \DIFdel{of software
  systems.
}%DIFDELCMD < \item
%DIFDELCMD <   %%%
\DIFdel{The }\emph{\DIFdel{Cognitive~Dimensions of~Notation}}%DIFAUXCMD
\DIFdelend ~\cite{CogDims} introduces a common vocabulary for software's
\emph{notational surface} and \DIFdelbegin \DIFdel{shows
  how they trade off and affect the performance of certain types of
  tasks.
}%DIFDELCMD < \end{itemize}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{for identifying their trade-offs.
}\DIFaddend 

\DIFdelbegin \DIFdel{Of these sources, the latter two bear the most obvious influence on }\DIFdelend \DIFaddbegin \DIFadd{The latter two directly influence }\DIFaddend our proposal. \DIFdelbegin \DIFdel{Our framework of ``technical dimensions'' continues the approach of the Cognitive
Dimensions to }\DIFdelend \DIFaddbegin \DIFadd{Firstly, the Cognitive
Dimensions are a set of qualitative properties which can be used to
analyze }\emph{\DIFadd{notations}}\DIFadd{. We wish to extend this approach to }\DIFaddend the
``rest'' of a system\DIFaddbegin \DIFadd{, }\DIFaddend beyond its notation\DIFdelbegin \DIFdel{. Our }\DIFdelend \DIFaddbegin \DIFadd{, with }\emph{\DIFadd{Technical}}
\DIFadd{Dimensions. Secondly, our }\DIFaddend individual dimensions naturally fall under
larger \emph{clusters} that we present in a regular format, similar to
the presentation of the classic Design Patterns. As for characteristics
identified by others, part of our contribution is to integrate them
under a common umbrella: liveness, pluralism, and uniformity metaphors
(``everything is an X'')\DIFdelbegin \DIFdel{are incorporated as dimensions already identified by the related work}\DIFdelend \DIFaddbegin \DIFadd{, which have already been identified by others,
become dimensions in our framework}\DIFaddend .

\DIFaddbegin \paragraph{\DIFadd{Methodology.}}

\DIFaddend We follow the attitude of \emph{Evaluating Programming
Systems}~\cite{EvProgSys} in distinguishing our work from HCI methods
and empirical evaluation. We are generally concerned with
characteristics that are not obviously amenable to statistical analysis
(e.g.~mining software repositories) or experimental methods like
controlled user studies, so numerical quantities are generally not
featured.

Similar development seems to be taking place in HCI research focused on
user interfaces. The UIST guidelines \DIFdelbegin \footnote{\DIFdel{https://uist.acm.org/uist2021/author-guide.html}}
%DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{UISTAuthor} }\hspace{0pt}%DIFAUXCMD
}\DIFaddend instruct authors
to evaluate system contributions holistically, and the community has
developed heuristics for such evaluation, such as \emph{Evaluating User
Interface Systems Research}~\cite{EvUISR}. Our set of dimensions offers
similar heuristics for identifying interesting aspects of programming
systems, though they focus more on underlying technical properties than
the surface interface.

Finally, we believe that the aforementioned paradigm shift from
programming systems to programming languages has hidden many ideas about
programming that are worthwhile recovering and developing further
\cite{ComplementaryBasic}. Thus our approach is related to the idea of
\emph{complementary science} developed by Chang~\cite{Chang} in the
context of history and philosophy of science. Chang argues that even in
disciplines like physics, superseded or falsified theories may still
contain interesting ideas worth documenting. In the field of
programming, where past systems are discarded for many reasons besides
empirical failure, Chang's \emph{complementary science} approach seems
particularly suitable.

\DIFdelbegin %DIFDELCMD < \hypertarget{what-we-are-trying-to-achieve}{%
%DIFDELCMD < \subsection{What we are trying to
%DIFDELCMD < achieve}\label{what-we-are-trying-to-achieve}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Programming systems deserve a theory too!}}
\DIFaddend 

In short, while there is a theory for programming languages, programming
\emph{systems} deserve a theory too. It should apply from the small
scale of language implementations to the vast scale of operating
systems. It should be possible to analyse the common and unique features
of different systems, to reveal new possibilities, and to build on past
work in an effective manner. In Kuhnian terms, it should enable a body
of ``normal science'': filling in the map of the space of possible
systems (Figure \ref{fig:tech-dims-diagram}), thereby forming a
knowledge repository for future designers.

\hypertarget{programming-systems}{%
\section{Programming systems}\label{programming-systems}}

\DIFdelbegin %DIFDELCMD < \note{JE there is a lot of historical narrative in this section that may not be strictly necessary}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{We intentionally use the term }\DIFdelend \DIFaddbegin \DIFadd{We introduce the notion of a }\DIFaddend \emph{programming system} \DIFdelbegin \DIFdel{to refer to a broad range of
systems which are programmable to a varying degree . This
section highlights a number of example families of programming systems}\DIFdelend \DIFaddbegin \DIFadd{through a number
of examples, classified following the style of Lehman \mbox{%DIFAUXCMD
\cite{SPEPrograms}
}\hspace{0pt}%DIFAUXCMD
into three broad types. These are loosely inspired by the notions of
}\emph{\DIFadd{languages}}\DIFaddend , \DIFdelbegin \DIFdel{following a roughly chronological order. This serves three purposes. First, looking at
a number of examples from the past helps build an
intuitive understanding of what we mean by a }\DIFdelend \DIFaddbegin \emph{\DIFadd{operating systems}} \DIFadd{and }\emph{\DIFadd{applications}}\DIFadd{:
}

\begin{itemize}
\item
  \textbf{\DIFadd{L-type programming systems}} \DIFadd{are software ecosystems built
  around a text-based }\DIFaddend programming \DIFdelbegin \DIFdel{system. Second, it }\DIFdelend \DIFaddbegin \emph{\DIFadd{language}}\DIFadd{. They consist of a set
  of tools such as compilers, debuggers, and profilers. These tools may
  exist as separate command-line programs, or within an Integrated
  Development Environment.
}\item
  \textbf{\DIFadd{O-type programming systems}} \DIFadd{resemble }\emph{\DIFadd{operating systems}}
  \DIFadd{in that they structure the execution environment and encompass the
  resources of an entire machine (physical or virtual). They provide a
  common interface for communication, both between the user and the
  computer, and between programs themselves.
}\item
  \textbf{\DIFadd{A-type programming systems}} \DIFadd{are programmable
  }\emph{\DIFadd{applications}}\DIFadd{. They are typically optimized for a specific
  domain, and offer a limited degree of programmability which may be
  increased with newer versions.
}\end{itemize}

\DIFadd{We will illustrate each of these types with several examples. This will
provide an intuition for the notion of a programming system and
establish a collection of go-to examples for the rest of the paper.
}

\hypertarget{l-type-programming-systems}{%
\subsection{L-type programming
systems}\label{l-type-programming-systems}}

\DIFadd{We see programming systems as (collections of) software artifacts that
make it possible to construct programs, debug them, and turn them into
operational, maintained, and evolvable artifacts running on an
appropriate hardware. Text-based programming languages sit within
programming systems whose boundaries are not explicitly defined. To
speak of a programming system, we need to consider a language with, at
minimum, an editor and a compiler or interpreter. However, the exact
boundaries are a design choice that significantly affects our analysis.
}

\paragraph{\DIFadd{Java with the Eclipse ecosystem.}}

\DIFadd{Java cannot be viewed as a programming system on its own, but it is one
if we consider it as embedded in an ecosystem of tools. There are
multiple ways to delineate this, resulting in different analyses. A
minimalistic programming system would consist of a text editor to write
Java code and a command line compiler. A more realistic system is Java
as embedded in the Eclipse IDE. The programming systems view }\DIFaddend allows us
to \DIFdelbegin \DIFdel{introduce example systems that we will use in the next
section to illustrate the individual technical dimensions. Third, studying the difference between systems in individual families is one
way of identifying and motivating interesting technical dimensions.
}\DIFdelend \DIFaddbegin \DIFadd{see all there is beyond the textual code. In the case of Eclipse,
this includes the debugger, refactoring tools, testing and modelling
tools, GUI designers, and so on. This delineation yields a programming
system that is powerful and convenient, but has a large number of
concepts and secondary notations.
}\DIFaddend 

\DIFdelbegin %DIFDELCMD < \hypertarget{interacting-with-computers}{%
%DIFDELCMD < \subsection{Interacting with
%DIFDELCMD < computers}\label{interacting-with-computers}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Haskell tools ecosystem.}}
\DIFaddend 

\DIFdelbegin \DIFdel{The key aspect of computers that enabled the rise of programming systems
was the ability for a programmer to interact one-on-one with a computer. This was not possible in }\DIFdelend \DIFaddbegin \DIFadd{Haskell is an even more language-focused programming system. It is used
through the command-line }\emph{\DIFadd{GHC}} \DIFadd{compiler and }\emph{\DIFadd{GHCi}} \DIFadd{REPL,
alongside a text editor that provides features like syntax highlighting
and auto-completion. In general, we can consider any editor that
supports the Language Server Protocol \mbox{%DIFAUXCMD
\cite{LSP}}\hspace{0pt}%DIFAUXCMD
.
}

\DIFadd{Haskell is mathematically rooted and relies on mathematical intuition
for understanding many of its concepts. This background is also
reflected in the notations it uses. In addition to }\DIFaddend the \DIFdelbegin \DIFdel{1950s when most computers were large and
operated in a
batch-processing mode.
Two historical developments enabled
such interactivity from }\DIFdelend \DIFaddbegin \DIFadd{concrete language
syntax for writing code, }\DIFaddend the \DIFaddbegin \DIFadd{ecosystem also uses an informal
mathematical notation for writing about Haskell (e.g.~in academic papers
or on the whiteboard). This provides an additional tool for manipulating
Haskell programs. Experiments on paper can provide a kind of rapid
feedback that other systems may provide through live programming.
}

\paragraph{\DIFadd{From REPLs to notebooks.}}

\DIFadd{A different kind of developer ecosystem that evolved around a
programming language is the Jupyter notebook platform. In Jupyter, data
scientists write scripts divided into notebook cells, execute them
interactively and see the resulting data and visualizations directly in
the notebook itself. This brings together the REPL, which dates back to
conversational implementations of Lisp in the }\DIFaddend 1960s\DIFaddbegin \DIFadd{, with literate
programming \mbox{%DIFAUXCMD
\cite{LiterateProg} }\hspace{0pt}%DIFAUXCMD
used in the late 1980s in Mathematica
1.0}\DIFaddend .
\DIFaddbegin 

\DIFadd{As a programming system, Jupyter has a number of interesting
characteristics. The primary outcome of programming is the notebook
itself, rather than a separate application to be compiled and run. The
code lives in a document format, interleaved with other notations. Code
is written in small parts that are executed quickly, offering the user
more rapid feedback than in conventional programming. A notebook can be
seen as a trace of how the result has been obtained, yet one often
problematic feature of notebooks is that some allow the user to run code
blocks out-of-order. The code manipulates mutable state that exists in a
``kernel'' running in the background. Thus, retracing one's steps in a
notebook is more subtle than in, say, Common Lisp, where the
}\texttt{\DIFadd{dribble}} \DIFadd{function would directly record the user's session to a
file.
}

\hypertarget{o-type-programming-systems}{%
\subsection{O-type programming
systems}\label{o-type-programming-systems}}

\DIFadd{The first O-type programming systems emerged in the 1960s when it became
possible to interact one-on-one with a computer. }\DIFaddend First, time-sharing
systems enabled interactive shared use of a computer via a teletype\DIFdelbegin \DIFdel{. Second, }\DIFdelend \DIFaddbegin \DIFadd{;
}\DIFaddend smaller computers such as the PDP-1 and PDP-8 provided similar direct
interaction, while 1970s workstations such as the Alto and Lisp Machines
added graphical displays and mouse input.

\DIFdelbegin %DIFDELCMD < \hypertarget{lisp}{%
%DIFDELCMD < \subsubsection{Lisp}\label{lisp}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{MacLisp and Interlisp.}}
\DIFaddend 

\DIFdelbegin \DIFdel{The Lisp programming language, in the form of }\DIFdelend LISP 1.5 \cite{LISP15} \DIFdelbegin \DIFdel{,
}\DIFdelend arrived before the rise of interactive computers\DIFdelbegin \DIFdel{. Nevertheless,
}\DIFdelend \DIFaddbegin \DIFadd{,
but }\DIFaddend the existence of an interpreter and the absence of declarations made
it natural to use Lisp interactively, with the first such
implementations appearing in the early 1960s. Two branches of the Lisp
family \DIFdelbegin \DIFdel{,}\footnote{\DIFdel{The Lisp family consists of several branches, including
  MacLisp, InterLisp, ZetaLisp, Common Lisp, Scheme, Racket, and
  Clojure. See }\emph{\DIFdel{The Evolution of Lisp}} %DIFAUXCMD
\DIFdel{\mbox{%DIFAUXCMD
\cite{LispEvolve}}\hspace{0pt}%DIFAUXCMD
.}} %DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{LispEvolve}}\hspace{0pt}%DIFAUXCMD
, }\DIFaddend MacLisp and the later Interlisp, \DIFdelbegin \DIFdel{fully embraced the
so-called }\DIFdelend \DIFaddbegin \DIFadd{embraced the
interactive }\DIFaddend ``conversational'' way of working\DIFdelbegin \DIFdel{. Interaction occured through the teletype
at first, later giving way to }\DIFdelend \DIFaddbegin \DIFadd{, first through a teletype
and later using }\DIFaddend the screen and keyboard.
\DIFdelbegin \DIFdel{Even on the teletype, the system
incorporated a number of ideas that remain popular with programming
systems today.
}\DIFdelend 

Both MacLisp and Interlisp adopted the idea of \emph{persistent address
space}. Both program code and program state were preserved when powering
off the system, and could be accessed and modified interactively as well
as programmatically using the \emph{same means}. \DIFdelbegin \DIFdel{This idea appeared on
time-sharing systems and culminated with the development of Lisp Machines , which }\DIFdelend \DIFaddbegin \DIFadd{Lisp Machines }\DIFaddend embraced
the idea that the machine runs continually and saves the state to disk
when needed. Today, \DIFdelbegin \DIFdel{while this is still not the
default state for systems running ``natively'' on some hardware, it is
}\DIFdelend \DIFaddbegin \DIFadd{this is }\DIFaddend widely seen in cloud-based services like
Google Docs \DIFdelbegin \DIFdel{, online IDEs, or
virtual machine and container images. }%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{One idea not widely seen today, yet }\DIFdelend \DIFaddbegin \DIFadd{and online IDEs. Another idea }\DIFaddend pioneered in MacLisp and
Interlisp \DIFdelbegin \DIFdel{,
}\DIFdelend was the use of \emph{structure editors}. These let programmers
work with Lisp data structures not as sequences of characters, but as
nested lists. In Interlisp, \DIFdelbegin \DIFdel{for example, }\DIFdelend the programmer would use commands such as
\texttt{*P} to print the current expression, or \texttt{*(2\ (X\ Y))} to
replace its second element with the argument \texttt{(X\ Y)}. The PILOT
system \cite{Pilot} \DIFdelbegin \DIFdel{, later integrated into Interlisp, }\DIFdelend offered even more sophisticated conversational
features. For typographical errors and other slips, it would offer an
automatic fix for the user to interactively accept, modifying the
program in memory and resuming execution.

\DIFdelbegin %DIFDELCMD < \hypertarget{smalltalk}{%
%DIFDELCMD < \subsubsection{Smalltalk}\label{smalltalk}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Smalltalk.}}
\DIFaddend 

Smalltalk \DIFdelbegin \DIFdel{came on the scene }\DIFdelend \DIFaddbegin \DIFadd{appeared }\DIFaddend in the 1970s \DIFdelbegin \DIFdel{, with the }\DIFdelend \DIFaddbegin \DIFadd{with a distinct }\DIFaddend ambition of providing
``dynamic media which can be used by human beings of all ages''
\cite{PersonalDynMedia}. The authors saw computers as \emph{meta-media}
that could become a range of other media for education, discourse,
creative arts, simulation and other applications not yet invented.
Smalltalk was designed for single-user workstations with a graphical
display, and pioneered this display not just for applications but also
for programming itself. \DIFdelbegin \DIFdel{This evolved over the history of Smalltalk. }\DIFdelend In Smalltalk 72, one wrote code in the bottom
half of the screen \DIFdelbegin \DIFdel{. When
editing a definition, the window became a structure editor logically
similar to that of Lisp, but controlled using a mouseand menus instead
of a teletype. Smalltalk 76 completed the transition from a
terminal-based interface to a graphical interface, and introduced the
}\DIFdelend \DIFaddbegin \DIFadd{using a structure editor controlled by a mouse, and
menus to edit definitions. In Smalltalk-76 and later, this had switched
to text editing embedded in a }\DIFaddend \emph{class browser} for navigating
through classes and \DIFdelbegin \DIFdel{modifying their code}\DIFdelend \DIFaddbegin \DIFadd{their methods}\DIFaddend .

\DIFdelbegin \DIFdel{Smalltalk shared a number of other characteristics with Lisp , although
its key concept was one of }\emph{\DIFdel{objects}} %DIFAUXCMD
\DIFdel{and }\emph{\DIFdel{message passing}}
%DIFAUXCMD
\DIFdel{rather than }\emph{\DIFdel{lists}}%DIFAUXCMD
\DIFdel{. They both differ from most modern programming
systemsby adopting the aforementioned }\DIFdelend \DIFaddbegin \DIFadd{Similarly to Lisp systems, Smalltalk adopts the }\DIFaddend persistent address space
model of programming \DIFdelbegin \DIFdel{, }\DIFdelend where all objects remain in memory\DIFaddbegin \DIFadd{, but based on
}\emph{\DIFadd{objects}} \DIFadd{and }\emph{\DIFadd{message passing}} \DIFadd{rather than }\emph{\DIFadd{lists}}\DIFaddend . Any
changes made to the system state by programming or execution are
preserved when the computer is turned off. \DIFdelbegin \DIFdel{The }\DIFdelend \DIFaddbegin \DIFadd{Lastly, the }\DIFaddend fact that much of
the Smalltalk environment \DIFdelbegin \DIFdel{was
}\DIFdelend \DIFaddbegin \DIFadd{is }\DIFaddend implemented in itself \DIFdelbegin \DIFdel{, a property shared with many later Lisp systems,
made }\DIFdelend \DIFaddbegin \DIFadd{makes }\DIFaddend it possible to
\DIFdelbegin \DIFdel{significantly }\DIFdelend \DIFaddbegin \DIFadd{extensively }\DIFaddend modify the system from within.

\DIFdelbegin %DIFDELCMD < \hypertarget{unix}{%
%DIFDELCMD < \subsubsection{UNIX}\label{unix}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{UNIX.}}
\DIFaddend 

\DIFdelbegin \DIFdel{Both }\DIFdelend \DIFaddbegin \DIFadd{We included }\DIFaddend Lisp and Smalltalk \DIFdelbegin \DIFdel{worked, to some extent, }\DIFdelend \DIFaddbegin \DIFadd{in the O-type because they function }\DIFaddend as
operating systems \DIFdelbegin \DIFdel{.
The }\DIFdelend \DIFaddbegin \DIFadd{in many ways. On specialized machines, like the Xerox
Alto and Lisp machines, the }\DIFaddend user started their machine directly in the
Lisp or Smalltalk environment and was able to do everything they needed
from \emph{within} the system. \DIFdelbegin \footnote{\DIFdel{When the Lisp and Smalltalk systems were
  implemented on specialized computers---InterLisp and Smalltalk on the
  Alto and Xerox D, ZetaLisp and Common Lisp on Lisp machines---the user
  would start their computers directly in the programming system
  environment. When implemented on commodity hardware, the user would
  resume a saved image of the system.}} %DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdel{This explains why it is worth
considering (especially programmer-oriented) operating systems as
programming systems too. A prime example of this is UNIX, a 1970s
operating system for time-sharing computers}\DIFdelend \DIFaddbegin \DIFadd{Nowadays, however, this experience is
associated with UNIX and its descendants on a vast range of commodity
machines}\DIFaddend .

\DIFdelbegin \DIFdel{Many }\DIFdelend \DIFaddbegin \DIFadd{UNIX illustrates the fact that many }\DIFaddend aspects of programming systems are
shaped by their intended target audience. \DIFdelbegin \DIFdel{UNIX was built }\DIFdelend \DIFaddbegin \DIFadd{Built }\DIFaddend for computer hackers\DIFdelbegin \DIFdel{themselves and,
as such,
has its interface }\DIFdelend \DIFaddbegin \DIFadd{,
its abstractions and interface are }\DIFaddend close to the machine. Although
\DIFdelbegin \DIFdel{UNIX is historically closely }\DIFdelend \DIFaddbegin \DIFadd{historically }\DIFaddend linked to the C \DIFdelbegin \DIFdel{programming language, it }\DIFdelend \DIFaddbegin \DIFadd{language, UNIX }\DIFaddend developed a
language-agnostic set of abstractions that make it possible to use
multiple programming languages in a single system. While everything is
an object in Smalltalk, the ontology of the UNIX system consists of
files, memory, executable programs, and running processes. \DIFdelbegin \DIFdel{Interestingly, there is an explicit stage distinction here, not present
in Smalltalk or Lisp}\DIFdelend \DIFaddbegin \DIFadd{Note the
explicit ``stage'' distinction here}\DIFaddend : UNIX distinguishes between volatile
\emph{memory} structures, which are lost when the system is shut down,
and non-volatile \emph{disk} structures that are preserved. \DIFdelbegin \DIFdel{The ontology of files, however, enables an open pluralistic environment}\DIFdelend \DIFaddbegin \DIFadd{This
distinction between types of memory is considered, by Lisp and
Smalltalk, to be an implementation detail to be abstracted over by their
persistent address space. Still, this did not prevent the UNIX ontology
from supporting a pluralistic ecosystem of different languages and
tools}\DIFaddend .

\DIFdelbegin %DIFDELCMD < \hypertarget{application-platforms}{%
%DIFDELCMD < \subsection{Application platforms}\label{application-platforms}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Early and late Web.}}
\DIFaddend 

The \DIFaddbegin \DIFadd{Web evolved from a system for sharing and organizing information to
a }\emph{\DIFadd{programming system}}\DIFadd{. Today, it consists of a wide range of
server-side programming tools, JavaScript and languages that compile to
it, and notations like HTML and CSS. As a programming system, the
``modern 2020s web'' is reasonably distinct from the ``early 1990s
web''. In the early web, JavaScript code was distributed in a form that
made it easy to copy and re-use existing scripts, which led to
enthusiastic adoption by non-experts---recalling the birth of
microcomputers like Commodore 64 with BASIC a decade earlier.
}

\DIFadd{In the ``modern web'', multiple programming languages treat JavaScript
as a compilation target, and JavaScript is also used as a language on
the server-side. This web is no longer simple enough to encourage
copy-and-paste remixing of code from different sites. However, it does
come with advanced developer tools that provide functionality resembling
early interactive programming systems like Lisp and Smalltalk. The
}\emph{\DIFadd{Document Object Model (DOM)}} \DIFadd{structure created by a web page is
transparent, accessible to the user and modifiable through the built-in
browser inspector tools. Third-party code to modify the DOM can be
injected via extensions. The DOM almost resembles the tree/graph model
of Smalltalk and Lisp images, lacking the key persistence property. This
limitation, however, is being addressed by Webstrates~\mbox{%DIFAUXCMD
\cite{Webstrates}}\hspace{0pt}%DIFAUXCMD
.
}

\hypertarget{a-type-programming-systems}{%
\subsection{A-type programming
systems}\label{a-type-programming-systems}}

\DIFadd{The }\DIFaddend previously discussed programming systems were either universal, \DIFdelbegin \DIFdel{in
that they did not
focus }\DIFdelend \DIFaddbegin \DIFadd{not
focusing }\DIFaddend on any particular kind of application, or \DIFdelbegin \DIFdel{they
were focused on broad
application areas. Lisp, for example, was designed
for }\DIFdelend \DIFaddbegin \DIFadd{targeted at broad
fields, such as Artificial Intelligence and }\DIFaddend symbolic data manipulation
in \DIFdelbegin \DIFdel{the context of Artificial
Intelligence, while FORTRAN focused on scientific computing. However, as
computers became more widely used, it became clear that there are more
narrow typical }\DIFdelend \DIFaddbegin \DIFadd{Lisp's case. In contrast, the A-type programming systems focus on
more narrow }\DIFaddend kinds of applications that need to be built. \DIFdelbegin \DIFdel{For those,
specialized programming systems began to appear. Although they are more
focused, they also }\DIFdelend \DIFaddbegin \DIFadd{Many }\DIFaddend support
programming based on rich interactions with specialized visual and
textual notations.

\DIFdelbegin %DIFDELCMD < \hypertarget{spreadsheets}{%
%DIFDELCMD < \subsubsection{Spreadsheets}\label{spreadsheets}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Spreadsheets.}}
\DIFaddend 

\DIFdelbegin \DIFdel{Spreadsheets, along with word processors, were the application that
turned personal computers from playthings for hackers into a business
tool. }\DIFdelend The first system, VisiCalc, became available in 1979 and helped analysts
perform budget calculations. \DIFdelbegin \DIFdel{Spreadsheets }\DIFdelend \DIFaddbegin \DIFadd{As programming systems, spreadsheets are
notable for their programming substrate (a two-dimensional grid) and
evaluation model (automatic re-evaluation). The programmability of
spreadsheets }\DIFaddend developed over time, acquiring features that made them into
powerful programming systems in a way VisiCalc was not. The final step
was the 1993 inclusion of \emph{macros} in Excel, later \DIFaddbegin \DIFadd{further }\DIFaddend extended
with \emph{Visual Basic for Applications}.
\DIFdelbegin \DIFdel{As programming systems, spreadsheets are notable for
their programming substrate (a grid) and evaluation model (automatic
re-evaluation).
}\DIFdelend 

\DIFdelbegin %DIFDELCMD < \hypertarget{hypercard}{%
%DIFDELCMD < \subsubsection{HyperCard}\label{hypercard}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{HyperCard.}}
\DIFaddend 

While spreadsheets were designed to solve problems in a specific
application area, \DIFdelbegin \DIFdel{the next system we consider }\DIFdelend \DIFaddbegin \DIFadd{HyperCard \mbox{%DIFAUXCMD
\cite{HyperCard} }\hspace{0pt}%DIFAUXCMD
}\DIFaddend was designed around a
particular application format. \DIFdelbegin \DIFdel{1987 saw HyperCard \mbox{%DIFAUXCMD
\cite{HyperCard}}\hspace{0pt}%DIFAUXCMD
, with
programs as }\DIFdelend \DIFaddbegin \DIFadd{Programs are }\DIFaddend ``stacks of cards''
containing multimedia components and controls such as buttons. These
controls \DIFdelbegin \DIFdel{could }\DIFdelend \DIFaddbegin \DIFadd{can }\DIFaddend be programmed with pre-defined operations like ``navigate
to another card'', or via the HyperTalk scripting language for anything
more sophisticated.

As a programming system, HyperCard is interesting for a couple of
reasons. It effectively combines visual and textual notation. Programs
appear the same way during editing as they do during execution. Most
notably, HyperCard supports gradual progression from the ``user'' role
to ``developer'': a user may first use stacks, then go on to edit the
visual aspects or choose pre-defined logic until, eventually, they learn
to program in HyperTalk.

\DIFdelbegin %DIFDELCMD < \hypertarget{developer-platforms}{%
%DIFDELCMD < \subsection{Developer platforms}\label{developer-platforms}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{technical-dimensions}{%
\section{Technical dimensions}\label{technical-dimensions}}
\DIFaddend 

\DIFdelbegin \DIFdel{Programming systems such as Smalltalk and HyperCard are
relatively
}\emph{\DIFdel{self-contained}}%DIFAUXCMD
\DIFdel{. It is clear what is }\emph{\DIFdel{part of}} %DIFAUXCMD
\DIFdel{the
system, and what is on the }\DIFdelend \DIFaddbegin \DIFadd{We present our proposed technical dimensions grouped under
}\emph{\DIFadd{clusters}}\DIFadd{. The clusters may be regarded as ``topics of interest''
or ``areas of inquiry'' when studying a given system, grouping together
related dimensions against which to measure it. We also include a
concise reference sheet on the next page, though it will make more sense
after reading the relevant sections.
}

\DIFadd{Each cluster is named and opens with a boxed }\emph{\DIFadd{summary}}\DIFadd{, followed by
a longer }\emph{\DIFadd{discussion}}\DIFadd{, and closes with a list of any
}\emph{\DIFadd{relations}} \DIFadd{to other clusters along with any }\emph{\DIFadd{references}} \DIFadd{if
applicable. Within the main discussion, individual }\emph{\DIFadd{dimensions}} \DIFadd{are
listed. Sometimes, a particular value along a dimension (or a
combination of values along several dimensions) can be recognized as a
familiar pattern---perhaps with a name already established in the
literature. These are marked as }\emph{\DIFadd{examples}}\DIFadd{. Finally, interspersed
discussion that is neither a }\DIFaddend \emph{\DIFdelbegin \DIFdel{outside}%DIFDELCMD < \MBLOCKRIGHTBRACE%%%
\DIFdel{.
For many systems that began to appear
in the late 1980s, this is not the
case.
To think about them, we have to
consider a number of components, some of which may be conventional
programming languages. The boundaries of these }\emph{\DIFdel{developer
platforms}} %DIFAUXCMD
\DIFdel{are less well-defined and we acknowledge that the exact
delineation we choose significantly affects our analysis. }\DIFdelend \DIFaddbegin \DIFadd{dimension}} \DIFadd{nor an }\emph{\DIFadd{example}} \DIFadd{is
introduced as a }\emph{\DIFadd{remark}}\DIFadd{.
}

\DIFadd{For space reasons, we are only able to include one cluster,
}\emph{\DIFadd{customizability}}\DIFadd{, in the main body of this paper. We encourage the
reader to peruse Appendix~\ref{dimensions-catalogue} for the full extent
of our proposed dimensions.
}\DIFaddend 

\DIFdelbegin %DIFDELCMD < \hypertarget{early-and-late-web}{%
%DIFDELCMD < \subsubsection{Early and late Web}\label{early-and-late-web}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{customizability}{%
\subsection{Customizability}\label{customizability}}
\DIFaddend 

\DIFdelbegin \DIFdel{The Web appeared in 1989 as a way of sharing and organizing information,
implementing the ideas of }\emph{\DIFdel{hypertext}}%DIFAUXCMD
\DIFdel{. The web gradually evolved
from an }\emph{\DIFdel{information sharing}} %DIFAUXCMD
\DIFdel{system to a }\emph{\DIFdel{developer platform}}
%DIFAUXCMD
\DIFdel{when client-side scripting using JavaScript became possible. The Web
ecosystem started to consist of
server-side and client-side programming
tools.
Today, the Web combines the notations of HTML, CSS, a wide range
of server-side programming systems as well as JavaScript, and many
languages that compile to JavaScript}\DIFdelend \DIFaddbegin \mybox{Once a program exists in the system, how can it be extended and modified?}

\DIFadd{Programming is a gradual process. We start either from nothing, or from
an existing program, and gradually extend and refine it until it serves
a given purpose. Programs created using different programming systems
can be refined to different extents, in different ways, at different
stages of their existence.
}

\includepdf[pages={2}]{table.pdf}

\DIFadd{Consider three examples. First, a program in a conventional programming
language like Java can be refined only by modifying its source code.
However, you may be able to do so by just adding new code, such as a new
interface implementation. Second, a spreadsheet can be modified at any
time by modifying the formulas or data it contains. There is no separate
programming phase. However, you have to modify the formulas directly in
the cell---there is no way of modifying it by specifying a change in a
way that is external to the cell. Third, a }\emph{\DIFadd{self-sustaining}}
\DIFadd{programming system, such as Smalltalk, does not make an explicit
distinction between ``programming'' and ``using'' phases, and it can be
modified and extended via itself. It gives developers the power to
experiment with the system and, in principle, replace it with a better
system from within.
}

\hypertarget{dimension-staging-of-customization}{%
\subsubsection{Dimension: staging of
customization}\label{dimension-staging-of-customization}}

\DIFadd{For systems that distinguish between different stages, such as writing
source code versus running a program, customization methods may be
different for each stage. In traditional programming languages,
customization is done by modifying or adding source code at the
programming stage, but there is no (automatically provided) way of
customizing the created programs once they are running.
}

\DIFadd{There are a number of interesting questions related to staging of
customization. First, what is the notation used for customization? This
may be the notation in which a program was initially created, but a
system may also use a secondary notation for customization (consider
Emacs using Emacs Lisp). For systems with a stage distinction, an
important question is whether such changes are }\emph{\DIFadd{persistent}}\DIFaddend .

\DIFaddbegin \emph{\DIFadd{Smalltalk, Interlisp and similar.}} \DIFaddend In \DIFdelbegin \DIFdel{the 1990s, the ``early Web'' became a widely used programming system
}\DIFdelend \DIFaddbegin \DIFadd{image-based programming
systems, there is generally no strict distinction between stages and so
a program can be customized during execution in the same way as during
development. The program image includes the programming environment.
Users of a program can open this, navigate to a suitable object or a
class (which serve as the }\emph{\DIFadd{addressable extension points}}\DIFadd{) and
modify that. Lisp-based systems such as }\emph{\DIFadd{Interlisp}} \DIFadd{follow a
similar model. Changes made directly to the image are persistent. The
PILOT system for Lisp \mbox{%DIFAUXCMD
\cite{Pilot} }\hspace{0pt}%DIFAUXCMD
offers an interactive way of
correcting errors when a program fails during execution. Such
corrections are then applied to the image and are thus persistent.
}

\emph{\DIFadd{Document Object Model (DOM) and Webstrates}}\DIFadd{: In the context of Web
programming, there is traditionally a stage distinction between
programming (writing the code and markup) and running (displaying a
page). However, the DOM can be also modified by browser Developer
Tools---either manually, by running scripts in a console, or by using a
userscript manager such as Greasemonkey. Such changes are not persistent
in the default browser state, but are made so by Webstrates
\mbox{%DIFAUXCMD
\cite{Webstrates} }\hspace{0pt}%DIFAUXCMD
which synchronize the DOM between the server and the
client. This makes the DOM collaborative, but not (automatically)
}\emph{\DIFadd{live}} \DIFadd{because of the complexities this implies for event handling.
}

\hypertarget{dimension-addressing-and-externalizability}{%
\subsubsection{Dimension: addressing and
externalizability}\label{dimension-addressing-and-externalizability}}

\DIFadd{Programs in all programming systems have a representation that may be
exposed through notation such as source code. When customizing a
program, an interesting question is whether a customization needs to be
done by modifying the original representation, or whether it can be done
by }\emph{\DIFadd{adding}} \DIFadd{something alongside the original structure}\DIFaddend .
\DIFdelbegin \DIFdel{JavaScript code was distributed in a form that made it easy to copy and re-use existing scripts, which led to enthusiastic adoption by non-experts. This is comparable to the birth of microcomputers like
Commodore 64 with BASIC a decade earlier}\DIFdelend \DIFaddbegin 

\DIFadd{In order to support customization through addition, a programming system
needs a number of characteristics introduced by Basman et
al.~\mbox{%DIFAUXCMD
\cite{Externalize,OpenAuthorial}}\hspace{0pt}%DIFAUXCMD
. First, the system needs to support
}\emph{\DIFadd{addressing}}\DIFadd{: the ability to refer to a part of the program
representation from the outside. Next, }\emph{\DIFadd{externalizability}} \DIFadd{means
that a piece of addressed state can be exhaustively transferred between
the system and the outside world. Finally, }\emph{\DIFadd{additive authoring}}
\DIFadd{requires that system behaviours can be }\emph{\DIFadd{changed}} \DIFadd{by simply
}\emph{\DIFadd{adding}} \DIFadd{a new expression containing addresses---in other words,
anything can be }\emph{\DIFadd{overriden}} \DIFadd{without being }\emph{\DIFadd{erased}}\DIFadd{. Of
particular importance is how addresses are specified and what extension
points in the program they can refer to. The system may offer an
automatic mechanism that makes certain parts of a program addressable,
or this task may be delegated to the programmer}\DIFaddend .

\DIFdelbegin \DIFdel{The Web ecosystem continued to
evolve.
In the 2000s, multiple
programming languagesstarted to treat JavaScript as a compilation
target, while JavaScript started to be used as a programming language on
the server-side. This
defines the ``late Web'' ecosystem, which is quite
different from its early incarnation. JavaScript code was no longer
simple enough to whimsically copy and paste, yet advanced developer
tools provided functionality resembling early interactive programming systems like Lisp and Smalltalk.
The }\emph{\DIFdel{Document Object Model (DOM)}}
%DIFAUXCMD
\DIFdel{structure created by a web page is transparent, }\DIFdelend \DIFaddbegin \emph{\DIFadd{Cascading Style Sheets (CSS)}}\DIFadd{: CSS is a prime example of additive
authoring within the Web programming system. It provides rich
addressability mechanisms that are partly automatic (when referring to
tag names) and partly manual (when using element IDs and class names).
Given a web page, it is possible to modify almost any aspect of its
appearance by simply }\emph{\DIFadd{adding}} \DIFadd{additional rules to a CSS file. The
Infusion project \mbox{%DIFAUXCMD
\cite{Infusion} }\hspace{0pt}%DIFAUXCMD
offers similar customizability
mechanisms, but for behaviour rather than just styling. There is also
the recent programming system Varv~\mbox{%DIFAUXCMD
\cite{Varv}}\hspace{0pt}%DIFAUXCMD
, which embodies additive
authoring as a core principle.
}

\emph{\DIFadd{Object Oriented Programming and Aspect Oriented Programming}}\DIFadd{: in
conventional programming languages, customization is done by modifying
the code itself. OOP and AOP make it possible to do so by adding code
independently of existing program code. In OOP, this requires manual
definition of extension points, i.e.~interfaces and abstract methods.
Functionality can then be added to a system by defining a new class
(although injecting the new class into existing code without
modification requires some form of configuration such as a dependency
injection container). AOP systems such as AspectJ \mbox{%DIFAUXCMD
\cite{AspectJ}
}\hspace{0pt}%DIFAUXCMD
provides a richer addressing mechanism. In particular, it makes it
possible to add functionality to the invocation of a specific method
(among other options) by using the }\emph{\DIFadd{method call pointcut}}\DIFadd{. This
functionality is similar to }\emph{\DIFadd{advising}} \DIFadd{in Pilot \mbox{%DIFAUXCMD
\cite{Pilot}}\hspace{0pt}%DIFAUXCMD
.
}

\hypertarget{dimension-self-sustainability}{%
\subsubsection{Dimension:
self-sustainability}\label{dimension-self-sustainability}}

\DIFadd{For most programming languages, programming systems, and ordinary
software applications, if one wants to customize beyond a certain point,
one must go beyond the facilities provided in the system itself. Most
programming systems maintain a clear distinction between the }\emph{\DIFadd{user
level}}\DIFadd{, where the system is used, and }\emph{\DIFadd{implementation level}}\DIFadd{, where
the source code of the system itself resides. If the user level does not
expose control over some property or feature, then one is forced to go
to the implementation level. In the common case this will be a
completely different language or system, with an associated learning
cost. It is also likely to be lower-level---lacking expressive
functions, features or abstractions of the user level---which makes for
a more tedious programming experience.
}

\DIFadd{It is possible, however, to carefully design systems to expose deeper
aspects of their implementation }\emph{\DIFadd{at the user level}}\DIFadd{, relaxing the
formerly strict division between these levels. For example, in the
research system }\emph{\DIFadd{3-Lisp}} \DIFadd{\mbox{%DIFAUXCMD
\cite{PRinPLs}}\hspace{0pt}%DIFAUXCMD
, ordinarily built-in
functions like the conditional }\texttt{\DIFadd{if}} \DIFadd{and error handling
}\texttt{\DIFadd{catch}} \DIFadd{are implemented in 3-Lisp code at the user level.
}

\DIFadd{The degree to which a system's inner workings are }\DIFaddend accessible to the user
\DIFdelbegin \DIFdel{and modifiable through the built-in browser debugging tools, and
third-party code to modify the structure can be injected via
extensions. In this, the DOM resembles the }\emph{\DIFdel{persistent image}} %DIFAUXCMD
\DIFdel{model.
The DOM
also inspired further research on image-based programming: Webstrates
\mbox{%DIFAUXCMD
\cite{Webstrates} }\hspace{0pt}%DIFAUXCMD
synchronizes DOM edits made in the browser to all
other clients connected to a single server}\DIFdelend \DIFaddbegin \DIFadd{level, we call }\emph{\DIFadd{self-sustainability}}\DIFadd{. At the maximal degree of this
dimension would reside ``stem cell''-like systems: those which can be
progressively evolved to arbitrary behavior without having to ``step
outside'' of the system to a lower implementation level. In a sense, any
difference between these systems would be merely a difference in initial
state, since any could be turned into any other.
}

\DIFadd{The other end, of minimal self-sustainability, corresponds to minimal
customizability: beyond the transient run-time state changes that make
up the user level of any piece of software, the user cannot change
anything without dropping down to the means of implementation of the
system. This would resemble a traditional end-user ``application''
focused on a narrow domain with no means to do anything else.
}

\DIFadd{The terms ``self-describing'' or ``self-implementing'' have been used
for this property, but they can invite confusion: how can a thing
describe itself? Instead, a system that can }\emph{\DIFadd{sustain itself}} \DIFadd{is an
easier concept to grasp. The examples that we see of high
self-sustainability all tend to be }\emph{\DIFadd{Operating System-like}}\DIFadd{. UNIX is
widely established as an operating system, while Smalltalk and Lisp have
been branded differently. Nevertheless, all three have shipped as the
operating systems of custom hardware, and have similar responsibilities.
Specifically: they support the execution of ``programs''; they define an
interface for accessing and modifying state; they provide standard
libraries of common functionality; they define how programs can
communicate with each other; they provide a user interface.
}

\emph{\DIFadd{UNIX}}\DIFadd{: Self-sustainability of UNIX is owed to the combination of
two factors. First, the system is implemented in binary files (via
ELF}\footnote{\DIFadd{Executable and Linkable Format.}}\DIFadd{) and text files (for
configuration). Second, these files are part of the user-facing
filesystem, so users can replace and modify parts of the system using
UNIX file interfaces.
}

\emph{\DIFadd{Smalltalk and COLAs}}\DIFadd{: Self-sustainability in Smalltalk is similar
to UNIX, but at a finer granularity and with less emphasis on whether
things reside in volatile (process) or non-volatile (file) storage. The
analogous points are that (1) the system is implemented as objects with
methods containing Smalltalk code, and (2) these are modifiable using
the class browser and code editor. Combined Object Lambda Architectures,
or COLAs~\mbox{%DIFAUXCMD
\cite{COLAs}}\hspace{0pt}%DIFAUXCMD
, are a theoretical system design to improve on the
self-sustainability of Smalltalk. This is achieved by generalizing the
object model to support relationships beyond classes}\DIFaddend .

\DIFdelbegin %DIFDELCMD < \hypertarget{repls-and-notebooks}{%
%DIFDELCMD < \subsubsection{REPLs and notebooks}\label{repls-and-notebooks}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{references}{%
\subsubsection{References}\label{references}}
\DIFaddend 

\DIFdelbegin \DIFdel{Another kind of
developer ecosystem which evolved from simple scripting
tools consists of modern data science tools, such as Jupyter, whose
roots date back to ``On-Line Systems'' developed in the 1960s.
The style
was exemplified in conversational implementations of
Lisp, where users
could type commands to be evaluated and
see the results printed; this
interaction became known as the REPL (Read-Eval-Print Loop). In the late
1980s, Mathematica 1.0 combined the REPL interaction with a notebook
document format that showed the
commands alongside visual outputs,
an
idea pioneered in work on }\emph{\DIFdel{literate programming}}
%DIFAUXCMD
\DIFdel{\mbox{%DIFAUXCMD
\cite{LiterateProg}}\hspace{0pt}%DIFAUXCMD
. }\DIFdelend \DIFaddbegin \DIFadd{In addition to the examples discussed above, the proceedings of
self-sustaining systems workshops
\mbox{%DIFAUXCMD
\cite{SelfSustaining2008,SelfSustaining2010} }\hspace{0pt}%DIFAUXCMD
provides numerous examples
of systems and languages that are able to bootstrap, implement, modify,
and maintain themselves; Gabriel's analysis of programming language
revolutions \mbox{%DIFAUXCMD
\cite{PLrev} }\hspace{0pt}%DIFAUXCMD
uses }\emph{\DIFadd{advising}} \DIFadd{in PILOT, related Lisp
mechanisms, and ``mixins'' in OOP to illustrate the difference between
the ``languages'' and ``systems'' paradigms.
}\DIFaddend 

\DIFdelbegin \DIFdel{Today, REPLs exist for many programming
}\DIFdelend \DIFaddbegin \hypertarget{relations}{%
\subsubsection{Relations}\label{relations}}

\begin{itemize}
\tightlist
\item
  \emph{\DIFadd{Flattening and factoring}} \DIFadd{(Section
  \ref{examples-flattening-and-factoring}): related in that
  ``customizability'' is a form of creating new programs from existing
  ones; factoring repetitive aspects into a reusable standard component
  library facilitates the same thing.
}\item
  \emph{\DIFadd{Interaction}} \DIFadd{(Section \ref{interaction}): this determines
  whether there are separate stages for running and writing programs and
  may thus influence what kind of customization is possible.
}\end{itemize}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\DIFadd{The technical dimensions framework is intended to assist designers of
programming systems. This section illustrates two ways in which it can
be used. First, we use the dimensions to analyze the recent programming
system Dark~\mbox{%DIFAUXCMD
\cite{DarkWeb}}\hspace{0pt}%DIFAUXCMD
, explaining how it relates to past work and
how it contributes to the state of the art. Second, we use technical
dimensions to identify a new unexplored point in the design space of
programming systems and envision a new design that could emerge from the
analysis.
}

\hypertarget{evaluating-programming-systems}{%
\subsection{Evaluating programming
systems}\label{evaluating-programming-systems}}

\DIFadd{Dark is a programming system for building ``serverless backends'',
i.e.~services that are used by web and mobile applications. It aims to
make building such services easier by ``removing accidental
complexity''}\footnote{\DIFadd{https://roadmap.darklang.com/goals-of-dark-v2.html}}
\DIFadd{resulting from the large number of systems typically involved in their
deployment and operation. This includes infrastructure for
orchestration, scaling, logging, monitoring and versioning. Dark
provides integrated tooling (Figure~\ref{fig:dark}) for development and
is described as }\emph{\DIFadd{deployless}}\DIFadd{, meaning that deploying code to
production is instantaneous.
}

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{dark.png}
  \caption{\DIFaddFL{The Dark programming environment showing a simple web service comprising a database, two HTTP endpoints and a worker.}\label{fig:dark}}
  \note{FROM https://medium.com/@wilk/dark-lang-an-uncommon-step-towards-the-future-of-programming-921cf7f38baf}
\end{figure}

\DIFadd{Dark illustrates the need for the broader perspective of programming
systems. Of course, it contains a programming language, which is
inspired by OCaml and F\#. But Dark's distinguishing feature is that it
eliminates the many secondary systems needed for deployment of modern
cloud-based services. Those exist outside of a typical programming
language, yet form a major part of the complexity of the overall
development process.
}

\DIFadd{With technical dimensions, we can go beyond the ``sales pitch'', look
behind the scenes, and better understand the interesting technical
aspects of Dark as a programming system.
}

\hypertarget{dimensional-analysis-of-dark}{%
\subsubsection{Dimensional analysis of
Dark}\label{dimensional-analysis-of-dark}}

\paragraph{\DIFadd{Modes of interaction and feedback loops.}}

\DIFadd{Conventional }\emph{\DIFadd{modes of interaction}}
\DIFadd{(\ref{dimension-modes-of-interaction}) include running, editing and
debugging. For modern web services, running refers to operation in a
cloud-based environment that typically comes with further kinds of
feedback (logging and monitoring). The key design decision of Dark is to
integrate all these different modes of interaction into a single one.
This tight integration allows Dark to provide a more immediate
}\emph{\DIFadd{feedback loop}} \DIFadd{(\ref{dimension-feedback-loops}) where code changes
become immediately available not just to the developer, but also to
external users. The integrated mode of interaction is reminiscent of the
image-based environment in Smalltalk; Dark advances the state of art by
using this model in a multi-user, cloud-based context.
}

\paragraph{\DIFadd{Feedback loops and error response.}}

\DIFadd{The integration of development and operation also makes it possible to
use }\emph{\DIFadd{errors}} \DIFadd{occurring during operation to drive development.
Specifically, when a Dark service receives a request that is not
supported, the user can build a handler to provide a response---taking
advantage of the live data that was sent as part of the request. In
terms of our dimensions, this is a kind of }\emph{\DIFadd{error response}}
\DIFadd{(\ref{dimension-error-response}) that was pioneered by the PILOT system
for Lisp~\mbox{%DIFAUXCMD
\cite{Pilot}}\hspace{0pt}%DIFAUXCMD
. Dark does this not just to respond to errors, but
also as the primary development mechanism, which we might call
}\emph{\DIFadd{Error-Driven Development.}} \DIFadd{This way, Dark users can construct
programs with respect to sample input values.
}

\paragraph{\DIFadd{Conceptual structure and learnability.}}

\DIFadd{Dark programs are expressed using high-level concepts that are specific
to the domain of server-side web programming: HTTP request handlers,
databases, workers and scheduled jobs. These are designed to reduce
accidental complexity and aim for high }\emph{\DIFadd{conceptual integrity}}
\DIFadd{(\ref{dimension-conceptual-integrity-vs.-openness}). At the level of
code, Dark uses a general-purpose functional language that emphasizes
certain concepts, especially records and pipelines. The high-level
concepts contribute to }\emph{\DIFadd{learnability}}
\DIFadd{(\ref{dimension-learnability}) of the system, because they are highly
domain-specific and will already be familiar to its intended users.
}

\paragraph{\DIFadd{Notational structure and uniformity.}}

\DIFadd{Dark uses a combination of graphical editor and code. The two aspects of
the notation follow the }\emph{\DIFadd{complementing notations}}
\DIFadd{(\ref{dimension-notational-structure}) pattern. The windowed interface
is used to work with the high-level concepts and code is used for
working with low-level concepts. At the high level, code is structured
in freely positionable boxes on a 2D surface. Unlike Boxer \mbox{%DIFAUXCMD
\cite{Boxer}}\hspace{0pt}%DIFAUXCMD
,
these boxes do not nest and the space cannot be used for other content
(say, for comments, architectural illustrations or other media). Code at
the low level is manipulated using a syntax-aware structure editor,
showing inferred types and computed live values for pure functions. It
also provides special editing support for records and pipelines,
allowing users to add fields and steps respectively.
}

\paragraph{\DIFadd{Factoring of complexity and automation.}}

\DIFadd{One of the advertised goals of Dark is to remove accidental complexity.
This is achieved by collapsing the heterogeneous stack of technologies
that are typically required for development, cloud deployment,
orchestration and operation. Dark hides this via }\emph{\DIFadd{factoring of
complexity}} \DIFadd{(\ref{dimension-factoring-of-complexity}). The advanced
infrastructure is provided by the Dark platform and is hidden from the
user. The infrastructure is programmed explicitly and there is no need
for sophisticated automation (\ref{dimension-level-of-automation}). This
factoring of functionality that was previously coded manually follows a
similar pattern as the development of garbage collection in high-level
programming }\DIFaddend languages.
\DIFdelbegin \DIFdel{Unlike in Lisp, they
are often separate from the running program. REPLs often maintain an
execution state independent of a running program and
there are many
strategies for prototyping code in a REPL before making it a part of an
ordinary compiled application. }\DIFdelend 

\DIFdelbegin \DIFdel{Notebooks for data science are a particularly interesting example. Their
primary output is the notebook itself,
rather than a separate
application to be compiled and run. The code lives in a document format,
interleaved with other notations. Code is written in small parts that are executed (almost)immediately, offering the user more rapid feedback
than in conventional programming . A notebook can be seen as a trace of
how the result has been obtained, yet one often problematic feature of
notebooks is that some allow the user to run code blocks out-of-order!
Thus, while a
Common Lisp REPL user could just }\texttt{\DIFdel{dribble}} %DIFAUXCMD
\DIFdel{their
session to a file,
retracing one's steps in a notebook can be rather
more subtle.}\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Customizability.}}
\DIFaddend 

\DIFdelbegin %DIFDELCMD < \hypertarget{haskell-and-other-languages}{%
%DIFDELCMD < \subsubsection{Haskell and other
%DIFDELCMD < languages}\label{haskell-and-other-languages}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{The Dark platform makes a clear distinction between the platform itself
and the user application, so }\emph{\DIFadd{self-sustainability}}
\DIFadd{(\ref{dimension-self-sustainability}) is not an objective. The strict
division between the platform and user (related to its aforementioned
}\emph{\DIFadd{factoring of complexity}}\DIFadd{) means that changes to Dark require
modifying the platform source code itself, which is available under a
license that solely allows using it for the purpose of contributing.
Similarly, applications themselves are developed by modifying and adding
code, requiring destructive access to it---so }\emph{\DIFadd{additive authoring}}
\DIFadd{(\ref{dimension-addressing-and-externalizability}) is not exhibited at
either level. Thanks to the integration of execution and development,
persistent changes may be made during execution (c.f. }\emph{\DIFadd{staging of
customization}}\DIFadd{, \ref{dimension-staging-of-customization}) but this is
done through the Dark editor, which is separate from the running
service.
}\DIFaddend 

\DIFdelbegin \DIFdel{The aforementioned 1990s paradigm shift from thinking about
}\DIFdelend \DIFaddbegin \hypertarget{technical-innovations-of-dark}{%
\subsubsection{Technical innovations of
Dark}\label{technical-innovations-of-dark}}

\DIFadd{This analysis reveals a number of interesting aspects of the Dark
programming system. The first is the tight integration of different
}\emph{\DIFadd{modes of interaction}} \DIFadd{which collapses a heterogeneous stack of
technologies, makes Dark }\emph{\DIFadd{learnable}}\DIFadd{, and allows quick feedback
from deployed services. The second is the use of }\DIFaddend \emph{\DIFdelbegin \DIFdel{systems}\DIFdelend \DIFaddbegin \DIFadd{error response}\DIFaddend }
to \DIFdelbegin \DIFdel{thinking about }\emph{\DIFdel{languages}} %DIFAUXCMD
\DIFdel{means that researchers
tend to emphasize the language side of programming. However, all
programming languages are a part of a richer ecosystem that consist of
editors and other tools.
In our analysis, we choose Haskell as our
example of a clearly }\emph{\DIFdel{language-focused}} %DIFAUXCMD
\DIFdel{programming system .
}\DIFdelend \DIFaddbegin \DIFadd{guide the development of HTTP handlers. Thanks to the technical
dimensions framework, each of these can be more precisely described. It
is also possible to see how they may be supported in other programming
systems. The framework also points to possible alternatives (and perhaps
improvements) such as building a more self-sustainable system that has
similar characteristics to Dark, but allows greater flexibility in
modifying the platform from within itself.
}\DIFaddend 

\DIFdelbegin \DIFdel{Like most programming languages, Haskell code can be }\DIFdelend \DIFaddbegin \hypertarget{exploring-the-design-space}{%
\subsection{Exploring the design
space}\label{exploring-the-design-space}}

\DIFadd{With a little work, technical dimensions can let us see patterns or gaps
in the design space by plotting their values on a simple scatterplot.
Here, we will look at two dimensions, }\emph{\DIFadd{notational
diversity}}\footnote{\DIFadd{This is simply the dimension we named as
  }\emph{\DIFadd{uniformity of notations}}
  \DIFadd{(\ref{dimension-uniformity-of-notations}), but flipped in the opposite
  direction.}} \DIFadd{and }\emph{\DIFadd{self-sustainability}}\DIFadd{, for the following
programming systems: Haskell, Jupyter notebooks, Boxer, HyperCard, the
Web, spreadsheets, Lisp, Smalltalk, UNIX, and COLAs.
}

\DIFadd{While our choice to identify and describe dimensions as qualitative
concepts was necessary for coming up with them, }\emph{\DIFadd{some}} \DIFadd{way of
generating numbers is clearly necessary for visualizing their
relationships like this. For simplicity,}\footnote{\DIFadd{There are undoubtedly
  many ways to turn our descriptions into various measures, with
  strengths and weaknesses for different purposes, but this is beyond
  the scope of the present paper. Here, we merely wish to demonstrate
  that such a thing is possible and show what one can do with the
  results.}} \DIFadd{we adopt the following scheme. For each dimension, we
distill the main idea into several yes/no questions
(Appendix~\ref{making-dimensions-quantitative}) that capture enough of
the distinctions we observe between the systems we wish to plot. Then,
for each system, we add up the number of ``yes'' answers and obtain a
plausible score for the dimension.
}

\begin{figure}
  \centering
  \includegraphics[width=0.6\linewidth]{plot-figure0.pdf}
  \caption{\DIFaddFL{Example programming systems (or system families) measured against }\emph{\DIFaddFL{self-sustainability}} \DIFaddFL{and }\emph{\DIFaddFL{notational diversity}}\DIFaddFL{, revealing an absence of systems with a high degree of both. }\label{fig:design-space-plot}}
\end{figure}

\DIFadd{Figure~\ref{fig:design-space-plot} shows the results we obtained with
our sets of questions. It shows that the A-types span a range of
notational diversity, but only within fairly low self-sustainability.
The O-types cluster in an ``island'' at the right, sharing identical
notational diversity and near-identical self-sustainability. There is
also a conspicuous blank space at the top-right, representing an
unexplored combination of high values on both dimensions. With other
pairs of dimensions, we might take this as evidence of an oppositional
relationship, such that more of one inherently means less of the other
(perhaps looking for a single new dimension that describes this better.)
In this case, though, there is no obvious conflict between having many
notations and being able to change a system from within. Therefore, we
interpret the gap as a new opportunity to try out: combine the
self-sustainability of COLAs with the notational diversity of Boxer and
Web development. In fact, this is more or less the forthcoming
dissertation of the primary author.
}

\hypertarget{conclusions}{%
\section{Conclusions}\label{conclusions}}

\DIFadd{There is a renewed interest in developing new programming systems. Such
systems go beyond the simple model of code }\DIFaddend written in a \DIFdelbegin \DIFdel{wide
range of text editors, some of which support assistance tools such as
syntax highlighting and auto-completion. These offer immediate feedback
while editing code, such as when highlighting type errors}\DIFdelend \DIFaddbegin \DIFadd{programming
language using a more or less sophisticated text editor. They combine
textual and visual notations, create programs through rich graphical
interactions, and challenge accepted assumptions about program editing,
execution and debugging. Despite the growing number of novel programming
systems, it remains difficult to evaluate the design of programming
systems and see how they improve over work done in the past. To address
the issue, we proposed a framework of ``technical dimensions'' that
captures essential characteristics of programming systems in a
qualitative but rigorous way}\DIFaddend .

\DIFdelbegin \DIFdel{Haskell is mathematically rooted and relies on mathematical intuition
for understanding many of
its concepts. This background is also
reflected in the notations it uses. In addition to the concrete language
syntax (used when writing code)
, }\DIFdelend \DIFaddbegin \DIFadd{The framework of technical dimensions puts the vast variety of
programming systems, past and present, on a common footing of
commensurability. This is crucial to enable the strengths of each to be
identified and, if possible, combined by designers of the next
generation of programming systems. As more and more systems are assessed
in the framework, a picture of the space of possibilities will gradually
emerge. Some regions will be conspicuously empty, indicating unrealized
possibilities that could be worth trying. In this way, a domain of
``normal science'' is created for the design of programming systems.
}

\acks

\DIFadd{(To be completed for publication.)
}

\appendix
\newpage

\hypertarget{making-dimensions-quantitative}{%
\section{Making dimensions
quantitative}\label{making-dimensions-quantitative}}

\DIFadd{To generate numerical co-ordinates for }\emph{\DIFadd{self-sustainability}} \DIFadd{and
}\emph{\DIFadd{notational diversity}}\DIFadd{, we split both dimensions into a small
number of yes/no questions and counted the ``yes'' answers for each
system. We came up with the questions informally, with the goal of
achieving three things:
}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \DIFadd{To capture the basic ideas or features of the dimension
}\item
  \DIFadd{To make prior impressions more precise (i.e.~to roughly match where we
  intuitively felt certain key systems fit, but provide precision and
  possible surprises for systems we were not as confident about.)
}\item
  \DIFadd{To be the fewest in number necessary to attain the above
}\end{enumerate}

\DIFadd{The results of this process were as follows, along with a brief
rationale for each question. Afterwards, we will close with some
remarks.
}

\newcommand{\y}{\ding{52}}
\newcommand{\n}{}

\hypertarget{self-sustainability}{%
\subsection{Self-sustainability}\label{self-sustainability}}

\DIFadd{Questions:
}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{\DIFadd{Can you add new items to system namespaces without a restart?}}
  \DIFadd{The canonical example of this is in JavaScript, where ``built-in''
  classes like }\texttt{\DIFadd{Array}} \DIFadd{or }\texttt{\DIFadd{Object}} \DIFadd{can be augmented at
  will (and destructively modified, but that would be a separate point).
  Concretely, if a user wishes to make a new }\texttt{\DIFadd{sum}} \DIFadd{operation
  available to all Arrays, they are not }\emph{\DIFadd{prevented}} \DIFadd{from
  straightforwardly adding the method to the Array prototype as if it
  were just an ordinary object (which it is). Having to re-compile or
  even restart the system would mean that this cannot be meaningfully
  achieved from within }\DIFaddend the \DIFdelbegin \DIFdel{Haskell ecosystem also uses an
informal mathematical notation, which is used when writing about Haskell
(e}\DIFdelend \DIFaddbegin \DIFadd{system}\DIFaddend . \DIFdelbegin \DIFdel{g.~in academic papers or on the whiteboard). This provides an
additional tool for manipulating Haskell programs and experimenting with them on paper }\emph{\DIFdel{in vitro}}%DIFAUXCMD
\DIFdel{, in ways that other systems may attempt to achieve through experimentation }\DIFdelend \DIFaddbegin \DIFadd{Conversely, being able to do this
  means that even ``built-in'' namespaces are modifiable by ordinary
  programs, which indicates less of a implementation level vs.~user
  level divide and seems important for self-sustainability.
}\item
  \emph{\DIFadd{Can programs generate programs and execute them?}} \DIFadd{This property,
  related to ``code as data'' or the presence of an }\texttt{\DIFadd{eval()}}
  \DIFadd{function, is a key requirement of self-sustainability. Otherwise,
  re-programming the system, beyond selecting from a predefined list of
  behaviors, will require editing an external representation and
  restarting it. If users can type text inside the system then they will
  be able to write code---yet this code will be inert unless the system
  can interpret internal data structures as programs and actually
  execute them.
}\item
  \emph{\DIFadd{Are changes persistent enough to encourage indefinite
  evolution?}} \DIFadd{If initial tinkering or later progress can be reset by
  accidentally closing a window, or preserved only through a convoluted
  process, then this discourages any long-term improvement of a system
  from within. For example, when developing a JavaScript application
  with web browser developer tools, it is possible to run arbitrary
  JavaScript in the console, yet these changes apply only to the running
  instance. After tinkering in the console with the advantage of
  concrete system state, one must still go back to the source code file
  and make the corresponding changes manually. When the page is
  refreshed to load the updated code, it starts from a fresh initial
  state. This means it is not worth using the }\emph{\DIFadd{running}} \DIFadd{system for
  any programming beyond tinkering.
}\item
  \emph{\DIFadd{Can you reprogram low-level infrastructure within the running
  system?}} \DIFadd{This is a hopefully faithful summary of how the COLAs work
  aims to go beyond Lisp and Smalltalk in this dimension.
}\item
  \emph{\DIFadd{Can the user interface be arbitrarily changed from }\DIFaddend within the
  system\DIFdelbegin \emph{\DIFdel{in vivo}}%DIFAUXCMD
\DIFdel{. }\DIFdelend \DIFaddbegin \DIFadd{?}} \DIFadd{Whether classed as ``low-level infrastructure'' or not, the
  visual and interactive aspects of a system are a significant part of
  it. As such, they need to be as open to re-programming as any other
  part of it to classify as truly self-sustainable.
}\end{enumerate}
\DIFaddend 

\DIFdelbegin %DIFDELCMD < \hypertarget{technical-dimensions}{%
%DIFDELCMD < \section{Technical dimensions}\label{technical-dimensions}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \begin{tabular}{ c  c c c  c c c c  c c c c }
\DIFadd{Question }& \rot{Haskell}      & \rot{Jupyter} & \rot{HyperCard} & \rot{Subtext}
         & \rot{Spreadsheets} & \rot{Boxer}   & \rot{Web}       & \rot{UNIX}
         & \rot{Smalltalk}    & \rot{Lisp}    & \rot{COLAs} \\
\hline
\DIFadd{1 }& & & & & & & \ding{52}& \ding{52}& \ding{52}& \ding{52}& \ding{52}\\
\DIFadd{2 }& & & & & & & \ding{52}& \ding{52}& \ding{52}& \ding{52}& \ding{52}\\
\DIFadd{3 }& & & \ding{52}& & \ding{52}& \ding{52}& & \ding{52}& \ding{52}& \ding{52}& \ding{52}\\
\DIFadd{4 }& & & & & & & & & & & \ding{52}\\
\DIFadd{5 }& & & & & & & & \ding{52}& \ding{52}& \ding{52}& \ding{52}\\
\hline
\DIFadd{Total }& \DIFadd{0 }& \DIFadd{0 }& \DIFadd{1 }& \DIFadd{0 }& \DIFadd{1 }& \DIFadd{1 }& \DIFadd{2 }& \DIFadd{4 }& \DIFadd{4 }& \DIFadd{4 }& \DIFadd{5 }\\
\end{tabular}
\DIFaddend 

\DIFdelbegin \DIFdel{We present our proposed technical dimensions grouped under
}\emph{\DIFdel{clusters}}%DIFAUXCMD
\DIFdel{. The clusters may be regarded as ``topics of interest'' or ``areas of inquiry'' when studying a given system, grouping together
related dimensions against which to measure it. We also include a concise reference sheet on the next page , though it will make more sense
after reading the relevant sections.
}\DIFdelend \DIFaddbegin \hypertarget{notational-diversity}{%
\subsection{Notational diversity}\label{notational-diversity}}
\DIFaddend 

\DIFdelbegin \DIFdel{Each cluster is named and opens with a boxed }%DIFDELCMD < \emph{%%%
\DIFdel{summary}%DIFDELCMD < \MBLOCKRIGHTBRACE%%%
\DIFdel{, followed by
a longer }\emph{\DIFdel{discussion}}%DIFAUXCMD
\DIFdel{, and closes with a list of
  any
}\emph{\DIFdel{relations}} %DIFAUXCMD
\DIFdel{to other clusters along with any }\emph{\DIFdel{references}} %DIFAUXCMD
\DIFdel{if
applicable.
Within the main discussion, individual }\emph{\DIFdel{dimensions}} %DIFAUXCMD
\DIFdel{are
listed. Sometimes, a particular value along a dimension (or a
combination of values along several dimensions) can be recognized as a
familiar pattern---perhaps with a name already established in the
literature.
These are marked as }\emph{\DIFdel{examples}}%DIFAUXCMD
\DIFdel{. Finally, interspersed
discussion that is neither a }\emph{\DIFdel{dimension}} %DIFAUXCMD
\DIFdel{nor an }\emph{\DIFdel{example}} %DIFAUXCMD
\DIFdel{is
introduced as a
}\emph{\DIFdel{remark}}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{Questions:
}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{\DIFadd{Are there multiple syntaxes for textual notation?}} \DIFadd{Obviously,
  having more than one textual notation should count for notational
  diversity. However, for this dimension we want to take into account
  notations beyond the strictly textual, so we do not want this to be
  the only relevant question. Ideally, things should be weighted so that
  having a wide diversity of notations within some }\emph{\DIFadd{narrow class}}
  \DIFadd{is not mistaken for notational diversity in a more global sense. We
  want to reflect that UNIX, with its vast array of different languages
  for different situations, can never be as notationally diverse as a
  system with many languages }\emph{\DIFadd{and}} \DIFadd{many graphical notations, for
  example.
}\item
  \emph{\DIFadd{Does the system make use of GUI elements?}} \DIFadd{This is a focused
  class of non-textual notations that many of our example systems
  exhibit.
}\item
  \emph{\DIFadd{Is it possible to view and edit data as tree structures?}} \DIFadd{Tree
  structures are extremely common in programming, but they are usually
  worked with as text in some way. A few of our examples provide a
  graphical notation for this common data structure, so this is one way
  they can be differentiated from the rest.
}\item
  \emph{\DIFadd{Does the system allow freeform arrangement and sizing of data
  items?}} \DIFadd{We still felt Boxer and spreadsheets exhibited something not
  covered by the previous three questions, which is this. Within their
  respective constraints of rendering trees as nested boxes and
  single-level grids, they both provide for notational variation that
  can be useful to the user's context. These systems }\emph{\DIFadd{could}} \DIFadd{have
  decided to keep boxes neatly placed or cells all the same size, but
  the fact that they allow these to vary scores an additional point for
  notational diversity.
}\end{enumerate}

\begin{tabular}{ c  c c c  c c c c  c c c c }
\DIFadd{Question }& \rot{Haskell}      & \rot{Jupyter} & \rot{HyperCard} & \rot{Subtext}
         & \rot{Spreadsheets} & \rot{Boxer}   & \rot{Web}       & \rot{UNIX}
         & \rot{Smalltalk}    & \rot{Lisp}    & \rot{COLAs} \\
\hline
\DIFadd{1 }& & & & & & & \ding{52}& \ding{52}& & & \ding{52}\\
\DIFadd{2 }& & \ding{52}& \ding{52}& \ding{52}& \ding{52}& \ding{52}& \ding{52}& & \ding{52}& & \\
\DIFadd{3 }& & & & \ding{52}& & \ding{52}& \ding{52}& & & \ding{52}& \\
\DIFadd{4 }& & & & & \ding{52}& \ding{52}& & & & & \\
\hline
\DIFadd{Total }& \DIFadd{0 }& \DIFadd{1 }& \DIFadd{1 }& \DIFadd{2 }& \DIFadd{2 }& \DIFadd{3 }& \DIFadd{3 }& \DIFadd{1 }& \DIFadd{1 }& \DIFadd{1 }& \DIFadd{1 }\\
\end{tabular}

\hypertarget{remarks-and-future-work}{%
\subsection{Remarks and future work}\label{remarks-and-future-work}}

\DIFadd{This task of quantifying dimensions forced us to drill down and decide
on more crisp definitions of what they should be. We recommend it as a
useful exercise even in the absence of a goal like generating a graph}\DIFaddend .

\DIFdelbegin \DIFdel{For space reasons, we are only able to include the ``interaction'' and
``customizability''clusters in the main body of the paper; the rest can
be found in the Appendix. }\DIFdelend \DIFaddbegin \DIFadd{It is worth clarifying the meaning of what we have done here. It must
not be overlooked that this settling down on one particular definition
does not replace or obsolete the general qualitative descriptions of the
dimensions that we start with. Clearly, there are far too many sources
of variation in our process to consider our results here as final,
objective, the single correct definition of these dimensions, or
anything in this vein. Each of these sources of variation suggests
future work for interested parties:
}\DIFaddend 

\DIFdelbegin %DIFDELCMD < \includepdf{table.pdf}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \paragraph{\DIFadd{Quantification goals.}}
\DIFaddend 

\DIFaddbegin \DIFadd{We sought numbers to generate a graph that roughly matched our own
intuitive placement of several example systems. In other words, we were
trying to make those intuitions more precise along with the dimensions
themselves. An entirely different approach would be to have no
``anchor'' at all, and to take whatever answers a given definition
produces as ground truth. However, this would demand more detail for
answering questions and generating them in the first place.
}

\paragraph{\DIFadd{Question generation.}}

\DIFadd{We generated our questions informally and stopped when it seemed like
there were enough to make the important distinctions between example
points. There is huge room for variation here, though it seems
particularly hard to generate questions in any rigorous manner. Perhaps
we could take our }\emph{\DIFadd{self-sustainability}} \DIFadd{questions to be drawn from
a large set of ``actions you can perform while the system is running'',
which could be parametrized more easily. Similarly, our }\emph{\DIFadd{notational
diversity}} \DIFadd{questions tried to take into account a few classes of
notations---a more sophisticated approach might be to just count the
notations in a wide range of classes.
}

\paragraph{\DIFadd{Answering the questions.}}

\DIFadd{We answered our questions by coming to a consensus on what made sense to
the three of us. Others may disagree with these answers, and tracing the
source of disagreement could yield insights for different questions that
both parties would answer identically. Useful information could also be
obtained from getting many different people to answer the questions and
seeing how much variation there is.
}

\paragraph{\DIFadd{What is ``Lisp'', anyway?}}

\DIFadd{The final major source of variation would be the labels we have assigned
to example points. In some cases (Boxer), there really is only one
system; in others (spreadsheets) there are several different
}\emph{\DIFadd{products}} \DIFadd{with different names, yet which are still similar enough
to plausibly analyze as the same thing; in still others (Lisp) we're
treating a family of related systems as a cohesive point in the design
space. It is understandable if some think this elides too many important
distinctions. In this case, they could propose splits into different
systems or sub-families, or even suggest how these families should be
treated as blobs within various sub-spaces.
}

\hypertarget{dimensions-catalogue}{%
\section{Dimensions catalogue}\label{dimensions-catalogue}}

\DIFaddend \hypertarget{interaction}{%
\subsection{Interaction}\label{interaction}}

\mybox{How do users manifest their ideas, evaluate the result, and generate new ideas in response?}

An essential aspect of programming systems is how the user interacts
with them when creating programs. Take the standard form of statically
typed, compiled languages with straightforward library linking: here,
programmers write their code in a text editor, invoke the compiler, and
read through error messages they get. After fixing the code to pass
compilation, a similar process might happen with runtime errors.

Other forms are yet possible. On the one hand, some typical interactions
like compilation or execution of a program may not be perceptible at
all. On the other hand, the system may provide various interfaces to
support the plethora of other interactions that are often important in
programming, such as looking up documentation, managing dependencies,
refactoring or pair programming.

We focus on the interactions where programmer interacts with the system
to construct a program with a desired behavior. To analyze those, we use
the concepts of \emph{gulf of execution} and \emph{gulf of evaluation}
from \emph{The Design of Everyday Things}~\cite{Norman}.

\hypertarget{dimension-feedback-loops}{%
\subsubsection{Dimension: feedback
loops}\label{dimension-feedback-loops}}

In using a system, one first has some idea and attempts to make it exist
in the software; the gap between the user's goal and the means to
execute the goal is known as the \emph{gulf of execution}. Then, one
compares the result actually achieved to the original goal in mind; this
crosses the \emph{gulf of evaluation}. These two activities comprise the
\emph{feedback loop} through which a user gradually realises their
desires in the imagination, or refines those desires to find out ``what
they actually want''.

A system must contain at least one such feedback loop, but may contain
several at different levels or specialized to certain domains. For each
of them, we can separate the gulf of execution and evaluation as
independent legs of the journey, with possibly different manners and
speeds of crossing them.

\begin{figure}
  \centering
  \includegraphics[width=0.5\linewidth]{feedback-loops.png}
  \caption{The nested feedback loops of a statically-checked programming language.\label{fig:feedback-loops}}
\end{figure}

For example, we can analyze statically checked \emph{programming
languages} (e.g.~Java, Haskell) into several feedback loops (Figure
\ref{fig:feedback-loops}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Programmers often think about design details and calculations on a
  whiteboard or notebook, even before writing code. This
  \emph{supplementary medium} has its own feedback loop, even though
  this is often not automatic.
\item
  The code is written and is then put through the static checker. An
  error sends the user back to writing code. In the case of success,
  they are ``allowed'' to run the program, leading into cycle 3.

  \begin{itemize}
  \tightlist
  \item
    The execution gulf comprises multiple cycles of the supplementary
    medium, plus whatever overhead is needed to invoke the compiler
    (such as build systems).
  \item
    The evaluation gulf is essentially the waiting period before static
    errors or a successful termination are observed. Hence this is
    bounded by some function of the length of the code (the same cannot
    be said for the following cycle 3.)
  \end{itemize}
\item
  With a runnable program, the user now evaluates the \emph{runtime}
  behavior. Runtime errors can send the user back to writing code to be
  checked, or to tweak dynamically loaded data files in a similar cycle.

  \begin{itemize}
  \tightlist
  \item
    The execution gulf here may include multiple iterations of cycle 2,
    each with its own nested cycle 1.
  \item
    The \emph{evaluation} gulf here is theoretically unbounded; one may
    have to wait a very long time, or create very specific conditions,
    to rule out certain bugs (like race conditions) or simply to
    consider the program as fit for purpose.
  \item
    By imposing \emph{static checks}, some bugs can be pushed earlier to
    the evaluation stage of cycle 2, reducing the likely size of the
    cycle 3 \emph{evaluation} gulf.
  \item
    On the other hand, this can make it harder to write statically valid
    code, which may increase the number of level-2 cycles, thus
    increasing the total \emph{execution} gulf at level 3.
  \item
    Depending on how these balance out, the total top-level feedback
    loop may grow longer or shorter.
  \end{itemize}
\end{enumerate}

\hypertarget{example-immediate-feedback}{%
\subsubsection{Example: immediate
feedback}\label{example-immediate-feedback}}

The specific case where the \emph{evaluation} gulf is minimized to be
imperceptible is known as \emph{immediate feedback}. Once the user has
caused some change to the system, its effects (including errors) are
immediately visible. This is a key ingredient of \emph{liveness}, though
it is not sufficient on its own. (See \emph{Relations})

The ease of achieving immediate feedback is obviously constrained by the
computational load of the user's effects on the system, and the system's
performance on such tasks. However, such ``loading time'' is not the
only way feedback can be delayed: a common situation is where the user
has to manually ask for (or ``poll'') the relevant state of the system
after their actions, even if the system finished the task quickly. Here,
the feedback could be described as \emph{immediate upon demand} yet not
\emph{automatically demanded}. For convenience, we choose to include the
latter criterion---automatic demand of result---in our definition of
immediate feedback.

In a \emph{REPL} or \emph{shell}, there is a \emph{main} cycle of typing
commands and seeing their output, and a \emph{secondary} cycle of typing
and checking the command line itself. The output of commands can be
immediate, but usually reflects only part of the total effects or even
none at all. The user must manually issue further commands afterwards,
to check the relevant state bit by bit. The secondary cycle, like all
typing, provides immediate feedback in the form of character ``echo'',
but things like syntax errors generally only get reported \emph{after}
the entire line is submitted. This evaluation gulf has been reduced in
the JavaScript console of web browsers, where the line is ``run'' in a
limited manner on every keystroke. Simple commands without
side-effects,\DIFaddbegin \footnote{\DIFadd{Of course, these are detected via some
  conservative over-approximation which excludes expressions that
  }\emph{\DIFadd{might}} \DIFadd{side-effect.}} \DIFaddend such as calls to pure functions, can give
instantly previewed results---though partially typed expressions and
syntax errors will not trigger previews.

\hypertarget{example-direct-manipulation}{%
\subsubsection{Example: direct
manipulation}\label{example-direct-manipulation}}

Direct manipulation \cite{DirectManip} is a special case of an immediate
feedback loop. The user sees and interacts with an artefact in a way
that is as similar as possible to real life; this typically includes
dragging with a cursor or finger in order to physically move a visual
item, and is limited by the particular haptic technology in use.

Naturally, because moving real things with one's hands does not involve
any waiting for the object to ``catch up'',\footnote{In some situations,
  such as steering a boat with a rudder, there is a delay between input
  and effect. But on closer inspection, this delay is between the rudder
  and the boat; we do not see the hand pass through the wheel like a
  hologram, followed by the wheel turning a second later. In real life,
  objects touched directly give immediate feedback; objects controlled
  further down the line might not!} direct manipulation is necessarily
an immediate-feedback cycle. If, on the other hand, one were to move a
figure on screen by typing new co-ordinates in a text box, then this
could still give \emph{immediate feedback} (if the update appears
instant and automatic) but would \emph{not} be an example of direct
manipulation.

\emph{Spreadsheets} contain a feedback loop for direct manipulation of
values and formatting, as in any other WYSIWYG application. \DIFdelbegin \DIFdel{They also
contain another }\DIFdelend \DIFaddbegin \DIFadd{Here, there
is feedback for every character typed and every change of style. This is
not the case in the other }\DIFaddend loop for formula editing and formula
invocation. \DIFdelbegin \DIFdel{Here, there is }\DIFdelend \DIFaddbegin \DIFadd{There, we see a }\DIFaddend larger execution gulf for designing and
typing formulas\DIFaddbegin \DIFadd{, where feedback is only given upon committing the
formula by pressing enter}\DIFaddend . This makes it an ``immediate feedback'' loop
only \emph{on-demand}\DIFaddbegin \DIFadd{, }\DIFaddend as defined above.

\hypertarget{dimension-modes-of-interaction}{%
\subsubsection{Dimension: modes of
interaction}\label{dimension-modes-of-interaction}}

The possible interactions in a programming system are typically
structured so that interactions, and the associated feedback loops, are
only available in certain \emph{modes}. For example, when creating a new
project, the user may be able to configure the project through a
conversational interface like \texttt{npm\ init} in modern JavaScript.
Such interactions are no longer available once the project is created.
This idea of interaction modes goes beyond just programming systems,
appearing in software engineering methodologies. In particular, having a
separate \emph{implementation} and \emph{maintenance} phase would be an
example of two modes.

\emph{Editing vs debugging.} A good example is the distinction between
\emph{editing} and \emph{debugging} mode. When debugging a program, the
user can modify the program state and get (more) immediate feedback on
what individual operations do. In some systems, one can even modify the
program itself during debugging. Such feedback loops are not available
outside of debugging mode.

\emph{Lisp systems} sometimes distinguish between \emph{interpreted} and
\emph{compiled} mode. The two modes do not differ just in the efficiency
of code execution, but also in the interactions they enable. In the
interpreted mode, code can be tested interactively and errors may be
corrected during the code execution (see \emph{Error response}). In the
compiled mode, the program can only be tested as a whole. The same two
modes also exist, for example, in some Haskell systems where the REPL
uses an interpreter (GHCi) distinct from the compiler (GHC).

\emph{Jupyter notebooks.} A programming system may also unify modes that
are typically distinct. The Jupyter notebook environment does not have a
distinct debugging mode; the user runs blocks of code and receives the
result. The single mode can be used to quickly try things out, and to
generate the final result, partly playing the role of both debugging and
editing modes. However, even Jupyter notebooks distinguish between
editing a document and running code.

\hypertarget{dimension-abstraction-construction}{%
\subsubsection{Dimension: abstraction
construction}\label{dimension-abstraction-construction}}

A necessary activity in programming is going between abstract schemas
and concrete instances. Abstractions can be constructed from concrete
examples, first principles or through other methods. A part of the
process may happen in the programmer's mind: they think of concrete
cases and come up with an abstract concept, which they then directly
encode in the system. Alternatively, a system can support these
different methods directly.

One option is to construct abstractions \emph{from first principles}.
Here, the programmer starts by defining an abstract entity such as an
interface in object-oriented programming languages. To do this, they
have to think what the required abstraction will be (in the mind) and
then encode it (in the system).

Another option is to construct abstractions \emph{from concrete cases}.
Here, the programmer uses the system to solve one or more concrete
problems and, when they are satisfied, the system guides them in
creating an abstraction based on their concrete case(s). In a
programming language IDE this manifests as the ``extract function''
refactor, whereas in other systems we see approaches like macro
recording.

\emph{Pygmalion.} In Pygmalion \cite{Pygmalion}, all programming is done
by manipulating concrete icons that represent concrete things. To create
an abstraction, you can use ``Remember mode'', which records the
operations done on icons and makes it possible to bind this recording to
a new icon.

\emph{Jupyter notebook.} In Jupyter notebooks, you are inclined to work
with concrete things, because you see previews after individual cells.
This discourages creating abstractions, because then you would not be
able to look inside at such a fine grained level.

\emph{Spreadsheets.} Up until the recent introduction of lambda
expressions into Excel, spreadsheets have been relentlessly concrete,
without any way to abstract and reuse patterns of computation other than
copy-and-paste.

\hypertarget{relations}{%
\subsubsection{Relations}\label{relations}}

\begin{itemize}
\tightlist
\item
  \emph{Errors} (Section \ref{errors}) A longer evaluation gulf delays
  the detection of errors. A longer execution gulf can increase the
  \emph{likelihood} of errors (e.g.~writing a lot of code or taking a
  long time to write it). By turning runtime bugs into statically
  detected bugs, the combined evaluation gulfs can be reduced.
\item
  \emph{Adoptability} (Section \ref{adoptability}): The \emph{execution}
  gulf is concerned with software using and programming in general. The
  time taken to realize an idea in software is affected by the user's
  familiarity and the system's \emph{learnability}.
\item
  \emph{Notation} (Section \ref{notation}): Feedback loops are related
  to \emph{notational structures}. In a system with multiple notations,
  each notation may have different associated feedback loops. The motto
  ``The thing on the screen is supposed to be the actual thing''
  \cite{NakedObjects}, adopted in the context of live programming,
  relates \emph{liveness} to a direct connection between surface and
  internal notations. The idea is that interactable objects should be
  equipped with faithful behavior, instead of being intangible shadows
  cast by the hidden \emph{real} object.
\end{itemize}

\DIFdelbegin %DIFDELCMD < \hypertarget{customizability}{%
%DIFDELCMD < \subsection{Customizability}\label{customizability}}
%DIFDELCMD < 

%DIFDELCMD < \mybox{Once a program exists in the system, how can it be extended and modified?}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Programming is a gradual process. We start either from nothing, or from
an existing program, and gradually extend and refine it until it serves
a given purpose. Programs created using different programming systems
can be refined to different extents, in different ways, at different
stages of their existence.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Consider three examples. First, a program in a conventional programming
language like Java can be refined only by modifying its source code.
However, you may be able to do so by just adding new code, such as a new
interface implementation. Second, a spreadsheet can be modified at any
time by modifying the formulas or data it contains. There is no separate
programming phase. However, you have to modify the formulas directly in
the cell---there is no way of modifying it by specifying a change in a
way that is external to the cell. Third, a }\emph{\DIFdel{self-sustaining}}
%DIFAUXCMD
\DIFdel{programming system, such as Smalltalk, does not make an explicit
distinction between ``programming'' and ``using'' phases, and it can be
modified and extended via itself. It gives developers the power to
experiment with the system and, in principle, replace it with a better
system from within.
}%DIFDELCMD < 

%DIFDELCMD < \hypertarget{dimension-staging-of-customization}{%
%DIFDELCMD < \subsubsection{Dimension: staging of
%DIFDELCMD < customization}\label{dimension-staging-of-customization}}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{For systems that distinguish between different stages, such as writing
source code versus running a program, customization methods may be
different for each stage. In traditional programming languages,
customization is done by modifying or adding source code at the
programming stage, but there is no (automatically provided) way of
customizing the created programs once they are running.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{There are a number of interesting questions related to staging of
customization. First, what is the notation used for customization? This
may be the notation in which a program was initially created, but a
system may also use a secondary notation for customization (consider
Emacs using Emacs Lisp). For systems with a stage distinction, an
important question is whether such changes are }\emph{\DIFdel{persistent}}%DIFAUXCMD
\DIFdel{.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\emph{\DIFdel{Smalltalk, Interlisp and similar.}} %DIFAUXCMD
\DIFdel{In image-based programming
systems, there is generally no strict distinction between stages and so
a program can be customized during execution in the same way as during
development. The program image includes the programming environment.
Users of a program can open this, navigate to a suitable object or a
class (which serve as the }\emph{\DIFdel{addressable extension points}}%DIFAUXCMD
\DIFdel{) and
modify that. Lisp-based systems such as }\emph{\DIFdel{Interlisp}} %DIFAUXCMD
\DIFdel{follow a
similar model. Changes made directly to the image are persistent. The
PILOT system for Lisp \mbox{%DIFAUXCMD
\cite{Pilot} }\hspace{0pt}%DIFAUXCMD
offers an interactive way of
correcting errors when a program fails during execution. Such
corrections are then applied to the image and are thus persistent.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\emph{\DIFdel{Document Object Model (DOM) and Webstrates}}%DIFAUXCMD
\DIFdel{: In the context of Web
programming, there is traditionally a stage distinction between
programming (writing the code and markup) and running (displaying a
page). However, the DOM can be also modified by browser Developer
Tools---either manually, by running scripts in a console, or by using a
userscript manager such as Greasemonkey. Such changes are not persistent
in the default browser state, but are made so by Webstrates
\mbox{%DIFAUXCMD
\cite{Webstrates} }\hspace{0pt}%DIFAUXCMD
which synchronize the DOM between the server and the
client. This makes the DOM collaborative, but not (automatically)
}\emph{\DIFdel{live}} %DIFAUXCMD
\DIFdel{because of the complexities this implies for event handling.
}%DIFDELCMD < 

%DIFDELCMD < \hypertarget{dimension-addressing-and-externalizability}{%
%DIFDELCMD < \subsubsection{Dimension: addressing and
%DIFDELCMD < externalizability}\label{dimension-addressing-and-externalizability}}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Programs in all programming systems have a representation that may be
exposed through notation such as source code. When customizing a
program, an interesting question is whether a customization needs to be
done by modifying the original representation, or whether it can be done
by }\emph{\DIFdel{adding}} %DIFAUXCMD
\DIFdel{something alongside the original structure.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{In order to support customization through addition, a programming system
needs a number of characteristics introduced by Basman et
al.~\mbox{%DIFAUXCMD
\cite{Externalize,OpenAuthorial}}\hspace{0pt}%DIFAUXCMD
. First, the system needs to support
}\emph{\DIFdel{addressing}}%DIFAUXCMD
\DIFdel{: the ability to refer to a part of the program
representation from the outside. Next, }\emph{\DIFdel{externalizability}} %DIFAUXCMD
\DIFdel{means
that a piece of addressed state can be exhaustively transferred between
the system and the outside world. Finally, }\emph{\DIFdel{open authoring}}
%DIFAUXCMD
\DIFdel{requires that system behaviours can be }\emph{\DIFdel{changed}} %DIFAUXCMD
\DIFdel{by simply
}\emph{\DIFdel{adding}} %DIFAUXCMD
\DIFdel{a new expression containing addresses---in other words,
anything can be }\emph{\DIFdel{overriden}} %DIFAUXCMD
\DIFdel{without being }\emph{\DIFdel{erased}}%DIFAUXCMD
\DIFdel{. Of
particular importance is how addresses are specified and what extension
points in the program they can refer to. The system may offer an
automatic mechanism that makes certain parts of a program addressable,
or this task may be delegated to the programmer.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\emph{\DIFdel{Cascading Style Sheets (CSS)}}%DIFAUXCMD
\DIFdel{: CSS is a prime example of a system
that offers open authoring with rich addressability mechanisms that are
partly automatic (when referring to tag names) and partly manual (when
using element IDs and class names). Given a web page, it is possible to
modify (almost) any aspects of its appearance by simply }\emph{\DIFdel{adding}}
%DIFAUXCMD
\DIFdel{additional rules to a CSS file. The Infusion project \mbox{%DIFAUXCMD
\cite{Infusion}
}\hspace{0pt}%DIFAUXCMD
offers similar customizability mechanisms, but for behaviour rather than
just styling.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\emph{\DIFdel{Object Oriented Programming and Aspect Oriented Programming}}%DIFAUXCMD
\DIFdel{: in
conventional programming languages, customization is done by modifying
the code itself. OOP and AOP make it possible to do so by adding code
independently of existing program code. In OOP, this requires manual
definition of extension points, i.e.~interfaces and abstract methods.
Functionality can then be added to a system by defining a new class
(although injecting the new class into existing code without
modification requires some form of configuration such as a dependency
injection container). AOP systems such as AspectJ \mbox{%DIFAUXCMD
\cite{AspectJ}
}\hspace{0pt}%DIFAUXCMD
provides a richer addressing mechanism. In particular, it makes it
possible to add functionality to the invocation of a specific method
(among other options) by using the }\emph{\DIFdel{method call pointcut}}%DIFAUXCMD
\DIFdel{. This
functionality is similar to }\emph{\DIFdel{advising}} %DIFAUXCMD
\DIFdel{in Pilot \mbox{%DIFAUXCMD
\cite{Pilot}}\hspace{0pt}%DIFAUXCMD
.
}%DIFDELCMD < 

%DIFDELCMD < \hypertarget{dimension-self-sustainability}{%
%DIFDELCMD < \subsubsection{Dimension:
%DIFDELCMD < self-sustainability}\label{dimension-self-sustainability}}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{For most programming languages, programming systems, and ordinary
software applications, if one wants to customize beyond a certain point,
one must go beyond the facilities provided in the system itself. Most
programming systems maintain a clear distinction between the }\emph{\DIFdel{user
level}}%DIFAUXCMD
\DIFdel{, where the system is used, and }\emph{\DIFdel{implementation level}}%DIFAUXCMD
\DIFdel{, where
the source code of the system itself resides. If the user level does not
expose control over some property or feature, then one is forced to go
to the implementation level. In the common case this will be a
completely different language or system, with an associated learning
cost. It is also likely to be lower-level---lacking expressive
functions, features or abstractions of the user level---which makes for
a more tedious programming experience.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{It is possible, however, to carefully design systems to expose deeper
aspects of their implementation }\emph{\DIFdel{at the user level}}%DIFAUXCMD
\DIFdel{, relaxing the
formerly strict division between these levels. For example, in the
research system }\emph{\DIFdel{3-Lisp}} %DIFAUXCMD
\DIFdel{\mbox{%DIFAUXCMD
\cite{PRinPLs}}\hspace{0pt}%DIFAUXCMD
, ordinarily built-in
functions like the conditional }\texttt{\DIFdel{if}} %DIFAUXCMD
\DIFdel{and error handling
}\texttt{\DIFdel{catch}} %DIFAUXCMD
\DIFdel{are implemented in 3-Lisp code at the user level.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The degree to which a system's inner workings are accessible to the user
level, we call }\emph{\DIFdel{self-sustainability}}%DIFAUXCMD
\DIFdel{. At the maximal degree of this
dimension would reside ``stem cell''-like systems: those which can be
progressively evolved to arbitrary behavior without having to ``step
outside'' of the system to a lower implementation level. In a sense, any
difference between these systems would be merely a difference in initial
state, since any could be turned into any other.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The other end, of minimal self-sustainability, corresponds to minimal
customizability: beyond the transient run-time state changes that make
up the user level of any piece of software, the user cannot change
anything without dropping down to the means of implementation of the
system. This would resemble a traditional end-user ``application''
focused on a narrow domain with no means to do anything else.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The terms ``self-describing'' or ``self-implementing'' have been used
for this property, but they can invite confusion: how can a thing
describe itself? Instead, a system that can }\emph{\DIFdel{sustain itself}} %DIFAUXCMD
\DIFdel{is an
easier concept to grasp. The examples that we see of high
self-sustainability all tend to be }\emph{\DIFdel{Operating System-like}}%DIFAUXCMD
\DIFdel{. UNIX is
widely established as an operating system, while Smalltalk and Lisp have
been branded differently. Nevertheless, all three have shipped as the
operating systems of custom hardware, and have similar responsibilities.
Specifically: they support the execution of ``programs''; they define an
interface for accessing and modifying state; they provide standard
libraries of common functionality; they define how programs can
communicate with each other; they provide a user interface.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\emph{\DIFdel{UNIX}}%DIFAUXCMD
\DIFdel{: Self-sustainability of UNIX is owed to the combination of
two factors. First, the system is implemented in binary files (via
ELF}\footnote{\DIFdel{Executable and Linkable Format.}}%DIFAUXCMD
\addtocounter{footnote}{-1}%DIFAUXCMD
\DIFdel{) and text files (for
configuration). Second, these files are part of the user-facing
filesystem, so users can replace and modify parts of the system using
UNIX file interfaces.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\emph{\DIFdel{Smalltalk and COLAs}}%DIFAUXCMD
\DIFdel{: Self-sustainability in Smalltalk is similar
to UNIX, but at a finer granularity and with less emphasis on whether
things reside in volatile (process) or non-volatile (file) storage. The
analogous points are that (1) the system is implemented as objects with
methods containing Smalltalk code, and (2) these are modifiable using
the class browser and code editor. Combined Object Lambda Architectures,
or COLAs \mbox{%DIFAUXCMD
\cite{COLAs}}\hspace{0pt}%DIFAUXCMD
, are a theoretical system design to improve on the
self-sustainability of Smalltalk. This is achieved by generalizing the
object model to support relationships beyond classes.
}%DIFDELCMD < 

%DIFDELCMD < \hypertarget{references}{%
%DIFDELCMD < \subsubsection{References}\label{references}}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{In addition to the examples discussed above, the proceedings of
self-sustaining systems workshops
\mbox{%DIFAUXCMD
\cite{SelfSustaining2008,SelfSustaining2010} }\hspace{0pt}%DIFAUXCMD
provides numerous examples
of systems and languages that are able to bootstrap, implement, modify,
and maintain themselves; Gabriel's analysis of programming language
revolutions \mbox{%DIFAUXCMD
\cite{PLrev} }\hspace{0pt}%DIFAUXCMD
uses }\emph{\DIFdel{advising}} %DIFAUXCMD
\DIFdel{in PILOT, related Lisp
mechanisms, and ``mixins'' in OOP to illustrate the difference between
the ``languages'' and ``systems'' paradigms.
}%DIFDELCMD < 

%DIFDELCMD < \hypertarget{relations-1}{%
%DIFDELCMD < \subsubsection{Relations}\label{relations-1}}
%DIFDELCMD < 

%DIFDELCMD < \begin{itemize}
\begin{itemize}%DIFAUXCMD
%DIFDELCMD < \tightlist
%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\emph{\DIFdel{Flattening and factoring}} %DIFAUXCMD
\DIFdel{(Section
  \ref{examples-flattening-and-factoring}): related in that
  ``customizability'' is a form of creating new programs from existing
  ones; factoring repetitive aspects into a reusable standard component
  library facilitates the same thing.
}%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\emph{\DIFdel{Interaction}} %DIFAUXCMD
\DIFdel{(Section \ref{interaction}): this determines
  whether there are separate stages for running and writing programs and
  may thus influence what kind of customization is possible.
}
\end{itemize}%DIFAUXCMD
%DIFDELCMD < \end{itemize}
%DIFDELCMD < 

%DIFDELCMD < \hypertarget{conclusions}{%
%DIFDELCMD < \section{Conclusions}\label{conclusions}}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{There is a renewed interest in developing new programming systems. Such
systems go beyond the simple model of code written in a programming
language using a more or less sophisticated text editor. They combine
textual and visual notations, create programs through rich graphical
interactions, and challenge accepted assumptions about program editing,
execution and debugging. Despite the growing number of novel programming
systems, it remains difficult to evaluate the design of programming
systems and see how they improve over work done in the past. To address
the issue, we proposed a framework of ``technical dimensions'' that
captures essential characteristics of programming systems in a
qualitative but rigorous way.
}%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The framework of technical dimensions puts the vast variety of
programming systems, past and present, on a common footing of
commensurability. This is crucial to enable the strengths of each to be
identified and, if possible, combined by designers of the next
generation of programming systems. As more and more systems are assessed
in the framework, a picture of the space of possibilities will gradually
emerge. Some regions will be conspicuously empty, indicating unrealized
possibilities that could be worth trying. In this way, a domain of
``normal science'' is created for the design of programming systems.
}%DIFDELCMD < 

%DIFDELCMD < \acks
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{(To be completed for publication.)
}%DIFDELCMD < 

%DIFDELCMD < \appendix
%DIFDELCMD < %%%
\section{\DIFdel{Appendix}}
%DIFAUXCMD
\addtocounter{section}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \hypertarget{notation}{%
\subsection{Notation}\label{notation}}

\mybox{How are the different textual / visual programming notations related?}

Programming is always done through some form of notation. We consider
notations in the most general sense and include any structured gesture
using textual or visual notation. Textual notations primarily include
programming languages, but also things like configuration files. Visual
notations include graphical programming languages. Other kinds of
structured gestures include user interfaces for constructing visual
elements used in the system.

\hypertarget{dimension-notational-structure}{%
\subsubsection{Dimension: notational
structure}\label{dimension-notational-structure}}

In practice, most programming systems use multiple notations. Different
notations can play different roles in the system. On the one hand,
multiple \emph{overlapping notations} can be provided as different ways
of programming the same aspects of the system. In this case, each
notation may be more suitable to different kinds of users, but may have
certain limitations (for example, a visual notation may have a limited
expressive power). On the other hand, multiple \emph{complementing
notations} may be used as the means for programming different aspects of
the system. In this case, programming the system requires using multiple
notations, but each notation may be more suitable for the task at hand;
think of how HTML describes document structure while JavaScript
specifies its behavior.

\hypertarget{example-overlapping-notations}{%
\subsubsection{Example: overlapping
notations}\label{example-overlapping-notations}}

A programming system may provide multiple notations for programming the
same aspect of the system. This is typically motivated by an attempt to
offer easy ways of completing different tasks: say, a textual notation
for defining abstractions and a visual notation for specifying concrete
structures. The crucial issue in this kind of arrangement is
\emph{synchronizing} the different notations; if they have different
characteristics, this may not be a straightforward mapping. For example,
source code may allow more elaborate abstraction mechanisms like loops,
which will appear as visible repetition in the visual notation. What
should such a system do when the user edits a single object that
resulted from such repetition? Similarly, textual notation may allow
incomplete expressions that do not have an equivalent in the visual
notation. For programming systems that use \emph{overlapping notations},
we need to describe how the notations are synchronized.

\emph{Sketch-n-Sketch} \cite{SnS} employs overlapping notations for
creating and editing SVG and HTML documents. The user edits documents in
an interface with a split-screen structure that shows source code on the
left and displayed visual output on the right. They can edit both of
these and changes are propagated to the other view. The code can use
abstraction mechanisms (such as functions) which are not completely
visible in the visual editor (an issue we return to in \emph{expression
geography} below). Sketch-n-Sketch can be seen as an example of a
\emph{projectional editor}.\footnote{Technically, traditional
  projectional editors usually work more directly with the abstract
  syntax tree of a programming
  language.\note{TODO: Insert some more references to research on "projectional editors"}}

\emph{UML Round-tripping.} Another example of a programming system that
utilizes the \emph{overlapping notations} structure are UML design tools
that display the program both as source code and as a UML diagram. Edits
in one result in automatic update of the other. An example is the
Together/J\footnote{https://www.mindprod.com/jgloss/togetherj.html}
system. To solve the issue of notation synchronization, such systems
often need to store additional information in the textual notation,
typically using a special kind of code comment. In this example, after
the user re-arranges classes in UML diagrams, the new locations need to
be updated in the code.

\hypertarget{example-complementing-notations}{%
\subsubsection{Example: complementing
notations}\label{example-complementing-notations}}

A programming system may also provide multiple complementing notations
for programming different aspects of its world. Again, this is typically
motivated by the aim to make specifying certain aspects of programming
easier, but it is more suitable when the different aspects can be more
clearly separated. The key issue for systems with complementing
notations is how the different notations are connected. The user may
need to use both notations at the same time, or they may need to
progress from one to the next level when solving increasingly complex
problems. In the latter case, the learnability of progressing from one
level to the next is a major concern.

\emph{Spreadsheets and HyperCard.} In Excel, there are three different
complementing notations that allow users to specify aspects of
increasing complexity: (i) the visual grid, (ii) formula language and
(iii) a macro language such as Visual Basic for Applications. The
notations are largely independent and have different degrees of
expressive power. Entering values in a grid cannot be used for
specifying new computations, but it can be used to adapt or run a
computation, for example when entering different alternatives in What-If
Scenario Analysis. More complex tasks can be achieved using formulas and
macros. A user gradually learns more advanced notations, but experience
with a previous notation does not help with mastering the next one. The
approach optimizes for easy learnability at one level, but introduces a
hurdle for users to surmount in order to get to the second level. The
notational structure of \emph{HyperCard} is similar and consists of (i)
visual design of cards, (ii) visual programming (via the GUI) with a
limited number of operations and (iii) HyperTalk for arbitrary
scripting.

\emph{Boxer and Jupyter.} Boxer \cite{Boxer} uses \emph{complementing
notations} in that it combines a visual notation (the layout of the
document and the boxes of which it consists) with textual notation (the
code in the boxes). Here, the textual notation is always nested within
the visual. The case of Jupyter notebooks is similar. The document
structure is graphical; code and visual outputs are nested as editable
cells in the document. This arrangement is common in many other systems
such as Flash or Visual Basic, which both combine visual notation with
textual code, although one is not nested in the other.

\hypertarget{dimensions-surface-notation-and-internal-notation}{%
\subsubsection{Dimensions: surface notation and internal
notation}\label{dimensions-surface-notation-and-internal-notation}}

All programming systems build up structures in memory, which we can
consider as an \emph{internal notation} not usually visible to the user.
Even though such structures might be revealed in a debugger, they are
hidden during normal operation. What the user interacts with instead is
the \emph{surface notation}, typically one of text or shapes on a
screen. Every interaction with the surface notation alters the internal
notation in some way, and the nature of this connection is worth
examining in more detail. To do this, we illustrate with a simplified
binary choice for the form of these notations.

\hypertarget{examples-implicit-vs.-explicit-structure}{%
\subsubsection{Examples: implicit vs.~explicit
structure}\label{examples-implicit-vs.-explicit-structure}}

Let us partition notations into two families. Notations with
\emph{implicit structure} present as a sequence of items, such as
textual characters or audio signal amplitudes. Those with \emph{explicit
structure} present as a tree or graph without an obvious order, such as
shapes in a vector graphics editor. These two types of notations can be
transformed into each other: the implicit structure contained in a
string can be \emph{parsed} into an explicit syntax tree, and an
explicit document structure might be \emph{rendered} into a sequence of
characters with the same implicit structure.

Now consider an interface to enter a personal name made up of a forename
and a surname. For the surface notation, there could be a single text
field to hold the names separated with a space; here, the sub-structure
is implicit in the string. Alternatively, there could be two fields
where the names are entered separately, and their separation is
explicit. A similar choice exists for the internal notation built up in
memory: is it a single string, or two separate strings?

We can see that these choices give four combinations. More
interestingly, they exhibit unique characters owing to two key
asymmetries. Firstly, surface notation is mostly used by humans, while
the internal notation is mostly used by the computer. Secondly, and most
significantly, computer programs can only work with explicit structure,
while humans can understand both explicit and implicit structure.
\joel{informal vs formal structure?} Because of the practical
consequences of this asymmetry, we will examine the combinations with
emphasis on the \emph{internal} notation first.

\hypertarget{examples-one-string-in-memory-implicitly-structured-internal-notation}{%
\subsubsection{Examples: one string in memory (implicitly structured
internal
notation)}\label{examples-one-string-in-memory-implicitly-structured-internal-notation}}

The simplest case here would be with implicit structure in the surface
notation, i.e.~a single text box for the full name. Edits to the surface
are straightforwardly mirrored interally and persisted to disk. This
corresponds to \emph{text editing}. We can generalize this to an idea of
\emph{sequence editing} if we view the fundamental act as
\emph{recording} events to a list over time. For text, these are key
presses; for an audio editing interface they would be samples of sound
amplitude.

In the other case, with two text boxes, we have \emph{sequence
rendering}. The information about the separation of the two strings,
present in the interface, is not quite ``thrown away'' but is made
\emph{implicit} as a space character in the string. This combination
corresponds to Visual Basic generating code from GUI forms, video
editors combining multiple clips and effects into a single stream, and
3D renderers turning scene graphs into pixels. Another example is
line-based diff tools, which provide side-by-side views and related
interfaces, yet must ultimately forward the user's changes to the
underlying text file.

Critically, in both of these cases, a computer program can only
manipulate the stored sequences \emph{as} sequences; that is, by
inserting, removing, or serially reading. The appealing feature here is
that these operations are simple to implement and may be re-usable
across many types of sequences. However, any further structure is
implicit and, to work with it programmatically, a user must write a
program to \emph{parse} it into something explicit. Furthermore, errors
introduced at this stage may simply be \emph{recorded} into the
sequence, only to be discovered much later in an attempt to use the
data.

\hypertarget{examples-two-strings-in-memory-explicitly-structured-internal-notation}{%
\subsubsection{Examples: two strings in memory (explicitly structured
internal
notation)}\label{examples-two-strings-in-memory-explicitly-structured-internal-notation}}

\joel{TODO: cite The Many Forms of a Single Fact}

With two text boxes, both notations match, so there is not much work to
do. As with sequence editing, edits on the surface can be mirrored to
the internal notation. This corresponds to vector graphics editors and
3D modelling tools, as well as \emph{structure editors} for programming
languages. For this reason we call this combination \emph{structure
editing}.

With a single text field, we have \emph{structure recovery.} Parsing
needs to happen each time the input changes. This style is found in the
DOM inspector in browser developer tools, where HTML can be edited as
text to make changes to the document tree structure. More generally,
this is the mode found in compilers and interpreters which accept
program source text yet internally work on tree and graph structures. It
is also possible to do a sort of structure editing this way, where the
experience is made to resemble text editing but the output is explicitly
structured.

In both of these cases, in order to write programs to transform,
analyze, or otherwise work with the digital artefact the user has
created, one can trivially navigate the stored structure instead of
parsing it for every use. Parsing is either done away with altogether or
is reduced to a transient process that happens during editing; this
means errors can be caught at the moment they are introduced instead of
remaining latent.

\hypertarget{dimension-primary-and-secondary-notations}{%
\subsubsection{Dimension: primary and secondary
notations}\label{dimension-primary-and-secondary-notations}}

In practice, most programming systems use multiple notations. Even in
systems based on traditional programming languages, the \emph{primary
notation} of the language is often supported by \emph{secondary
notations} such as annotations encoded in comments and build tool
configuration files. However, it is possible for multiple notations to
be primary, especially if they are \emph{overlapping} as defined
earlier.

\emph{Programming languages.} Programming systems built around
traditional programming languages typically have further notations or
structured gestures associated with them. The primary notation in UNIX
is the C programming language. Yet this is enclosed in a programming
\emph{system} providing a multi-step mechanism for running C code via
the terminal, assisted by secondary notations such as shell scripts.
Some programming systems attempt to integrate tools that normally rely
on secondary notations into the system itself, reducing the number of
secondary notations that the programmer needs to master. For example, in
the Smalltalk descendant Pharo, versioning and package management is
done from within Pharo, removing the need for secondary notation such as
\texttt{git} commands and dependency configuration files.\footnote{The
  tool for versioning and package management in Pharo can still be seen
  as an \emph{internal} domain-specific language and thus as a secondary
  notation, but its basic structure is \emph{shared} with other
  notations in the Pharo system.}

\emph{Haskell.} In Haskell, the primary notation is the programming
language, but there are also a number of secondary notations. Those
include package managers (e.g.~the \texttt{cabal.project} file) or
configuration files for Haskell build tools. More interestingly, there
is also an informal mathematical notation associated with Haskell that
is used when programmers discuss programs on a whiteboard or in academic
publications. The idea of having such a mathematical notation dates back
to the \emph{Report on Algol 58} \cite{Alg58}, which explicitly defined
a ``publication language'' for ``stating and communicating problems''
using Greek letters and subscripts.

\hypertarget{dimension-expression-geography}{%
\subsubsection{Dimension: expression
geography}\label{dimension-expression-geography}}

A crucial feature of a notation is the relationship between the
structure of the notation and the structure of the behavior it encodes.
Most importantly, do \emph{similar expressions} in a particular notation
represent \emph{similar behavior}?\footnote{See Basman's
  \cite{NotYetCraft} similar discussion of ``density''.} Visual
notations may provide a more or less direct mapping. On the one hand,
similar-looking code in a block language may mean very different things.
On the other hand, similar looking design of two HyperCard cards will
result in similar looking cards---the mapping between the notation and
the logic is much more direct.

\emph{C/C++ expression language.} In textual notations, this may easily
not be the case. Consider the two C conditionals:

\begin{itemize}
\tightlist
\item
  \texttt{if\ (x==1)\ \{\ ...\ \}} evaluates the Boolean expression
  \texttt{x==1} to determine whether \texttt{x} equals \texttt{1},
  running the code block if the condition holds.
\item
  \texttt{if\ (x=1)\ \{\ ...\ \}} \emph{assigns} \texttt{1} to the
  variable \texttt{x}. In C, assignment is an expression
  \emph{returning} the assigned value, so the result \texttt{1} is
  interpreted as \texttt{true} and the block of code is \emph{always}
  executed.
\end{itemize}

A notation can be designed to map better to the logic behind it, for
example, by requiring the user to write \texttt{1==x}. This solves the
above problem as \texttt{1} is a literal rather than a variable, so it
cannot be assigned to (\texttt{1=x} is a compile error).

\hypertarget{dimension-uniformity-of-notations}{%
\subsubsection{Dimension: uniformity of
notations}\label{dimension-uniformity-of-notations}}

One common concern with notations is the extent to which they are
uniform. A uniform notation can express a wide range of things using
just a small number of concepts. The primary example here is
S-expressions from Lisp. An S-expression is either an atom or a pair of
S-expressions written \texttt{(s1\ .\ s2)}. By convention, an
S-expression \texttt{(s1\ .\ (s2\ .\ (s3\ .\ nil)))} represents a list,
written as \texttt{(s1\ s2\ s3)}. In Lisp, uniformity of notations is
closely linked to uniformity of representation.\footnote{Notations
  generally are closely linked to representation in that the notation
  may mirror the structures used for program representation. Basman et
  al.~\cite{Externalize} refer to this as a distinction between ``dead''
  notation and ``live'' representation forms).} In the idealized model
of LISP 1.5, the data structures represented by an S-expression are what
exists in memory. In real-world Lisp systems, the representation in
memory is more complex. A programming system can also take a very
different approach and fully separate the notation from the in-memory
representation.

\emph{Lisp systems.} In Lisp, source code is represented in memory as
S-expressions, which can be manipulated by Lisp primitives. In addition,
Lisp systems have robust macro processing as part of their semantics:
expanding a macro revises the list structure of the code that uses the
macro. Combining these makes it possible to define extensions to the
system in Lisp, with syntax indistinguishable from Lisp. Moreover, it is
possible to write a program that constructs another Lisp program and not
only run it interpretively (using the \texttt{eval} function) but
compile it at runtime (using the \texttt{compile} function) and execute
it. Many domain-specific languages, as well as prototypes of new
programming languages (such as Scheme), were implemented this way. Lisp
the language is, in this sense, a ``programmable programming language''.
\cite{LispIntro,ProgProgLang}

\hypertarget{references}{%
\subsubsection{References}\label{references}}

\emph{Cognitive Dimensions of Notation} \cite{CogDims} provide a
comprehensive framework for analysing individual notations, while our
focus here is on how multiple notations are related and how they are
structured. It is worth noting that the Cognitive Dimensions also define
\emph{secondary notation}, but in a different sense to ours. For them,
secondary notation refers to whether a notation allows including
redundant information such as color or comments for readability
purposes.

The importance of notations in the practice of science, more generally,
has been studied by \cite{PaperTools} as ``paper tools''. These are
formula-like entities which can be manipulated by humans in lieu of
experimentation, such as the aforementioned mathematical notation in
Haskell: a ``paper tool'' for experimentation on a whiteboard.
Programming notations are similar, but they are a way of communicating
with a machine; the experimentation does not happen on paper alone.

\DIFdelbegin %DIFDELCMD < \hypertarget{relations}{%
%DIFDELCMD < \subsubsection{Relations}\label{relations}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{relations-1}{%
\subsubsection{Relations}\label{relations-1}}
\DIFaddend 

\begin{itemize}
\tightlist
\item
  \emph{Interaction} (Section \ref{interaction}): The feedback loops
  that exist in a programming system are typically associated with
  individual notations. Different notations may also have different
  feedback loops.
\item
  \emph{Adoptability} (Section \ref{adoptability}): Notational structure
  can affect learnability. In particular, complementing notations may
  require (possibly different) users to master multiple notations.
  Overlapping notations may improve learnability by allowing the user to
  edit the program in one way (perhaps visually) and see the effect in
  the other notation (such as code.)
\item
  \emph{Errors} (Section \ref{errors}). A process that merely records
  user actions in a sequence (such as text editing) will, in particular,
  record any \emph{errors} the user makes and defer their handling to
  later use of the data, keeping the errors \emph{latent}. A process
  which instead treats user actions as edits to a structure, with
  constraints and correctness rules, will be able to catch errors at the
  moment they are introduced and ensure the data coming out is
  error-free.
\end{itemize}

\hypertarget{conceptual-structure}{%
\subsection{Conceptual Structure}\label{conceptual-structure}}

\mybox{How is meaning constructed? How are internal and external incentives balanced?}

\hypertarget{dimension-conceptual-integrity-vs.-openness}{%
\subsubsection{Dimension: conceptual integrity
vs.~openness}\label{dimension-conceptual-integrity-vs.-openness}}

The evolution of programming systems has led away from \emph{conceptual
integrity} towards an intricate ecosystem of specialized technologies
and industry standards. Any attempt to unify parts of this ecosystem
into a coherent whole will create \emph{incompatibility} with the
remaining parts, which becomes a major barrier to adoption. Designers
seeking adoption are pushed to focus on localized incremental
improvements that stay within the boundaries established by existing
practice. This creates a tension between how highly they can afford to
value conceptual elegance, and how open they are to the pressures
imposed by society. We will turn to both of these opposite
ends---\emph{integrity} and \emph{openness}---in more detail.

\hypertarget{example-conceptual-integrity}{%
\subsubsection{Example: conceptual
integrity}\label{example-conceptual-integrity}}

\begin{quote}
I will contend that Conceptual Integrity is the most important
consideration in system design. It is better to have a system omit
certain anomalous features and improvements, but to reflect one set of
design ideas, than to have one that contains many good but independent
and uncoordinated ideas. (Fred~Brooks, \emph{Aristocracy, Democracy and
System Design} \cite{brooks95aristo})
\end{quote}

\note{The essence of this style can be captured by the phrase the right thing. To such a designer it is important to get all of the following characteristics right: Simplicity  Correctness  Consistency  Completeness --- Richard Gabriel}

\begin{quote}
Conceptual integrity arises not (simply) from one mind or from a small
number of agreeing resonant minds, but from sometimes hidden co-authors
and the thing designed itself. (Richard ~Gabriel, \emph{Designed As
Designer} \cite{DesignedAsDesigner})
\end{quote}

Conceptual integrity strives to reduce complexity at the source; it
employs \emph{unified concepts} that may \emph{compose orthogonally} to
generate diversity. Perhaps the apotheosis of this approach can be found
in early Smalltalk and Lisp machines, which were complete programming
systems built around a single language. They incorporated capabilities
commonly provided \emph{outside} the programming language by operating
systems and databases. Everything was done in one language, and so
everything was represented with the datatypes of that language. Likewise
the libraries and idioms of the language were applicable in all
contexts. Having a \emph{lingua franca} avoided much of the friction and
impedance mismatches inherent to multi-language systems. A similar drive
exists in the Python programming language, which follows the principle
that ``There should be one---and preferably only one---obvious way to do
it'' in order to promote community consensus on a single coherent style.

In addition to Smalltalk and Lisp, many programming languages focus on
one kind of data structure \cite{MemMod}:

\begin{itemize}
\tightlist
\item
  In COBOL, data consists of nested records as in a business form.
\item
  In Fortran, data consists of parallel arrays.
\item
  In SQL, data is a set of relations with key constraints.
\item
  In scripting languages like Python, Ruby, and Lua, much data takes the
  form of string-indexed hash tables.
\end{itemize}

Finally, many languages are \emph{imperative}, staying close to the
hardware model of addressable memory, lightly abstracted into primitive
values and references into mutable arrays and structures. On the other
hand, \emph{functional} languages hide references and treat everything
as immutable structured values. This conceptual simplification benefits
certain kinds of programming, but can be counterproductive when an
imperative approach is more natural, such as in external input/output.

\hypertarget{example-conceptual-openness}{%
\subsubsection{Example: conceptual
openness}\label{example-conceptual-openness}}

\emph{Perl, contra Python}. In contrast to Python's outlook, Perl
proclaims ``There is more than one way to do it'' and considers itself
``the first postmodern programming language'' \cite{Perl}. ``Perl
doesn't have any agenda at all, other than to be maximally useful to the
maximal number of people. To be the duct tape of the Internet, and of
everything else.'' The Perl way is to accept the status quo of evolved
chaos and build upon it using duct tape and ingenuity. Taken to the
extreme, a programming system becomes no longer a \emph{system},
properly speaking, but rather a \emph{toolkit for improvising}
assemblages of \emph{found} software. Perl can be seen as championing
the values of \emph{pluralism}, \emph{compatibility}, or
\emph{conceptual openness} over conceptual integrity. This philosophy
has been called \emph{Postmodern Programming} \cite{PoMoProNotes}.

\emph{C++, contra Smalltalk}. Another case is that of C++, which added
to C the Object-Oriented concepts developed by Smalltalk while remaining
100\% compatible with C, down to the level of ABI and performance. This
strategy was enormously successful for adoption, but came with the
tradeoff of enormous complexity compared to languages designed from
scratch for OO, like Smalltalk, Ruby, and Java.

\emph{Worse, contra Better}. Richard Gabriel first described this
dilemma in his influential 1991 essay \emph{Worse is Better} \cite{WIB}
analyzing the defeat of Lisp by UNIX and C. Because UNIX and C were so
easy to port to new hardware, they were ``the ultimate computer
viruses'' despite providing only ``about 50\%--80\% of what you want
from an operating system and programming language''. Their conceptual
openness meant that they adapted easily to the evolving conditions of
the external world. The tradeoff was decreased conceptual integrity,
such as the undefined behaviours of C, the junkyard of working
directories, and the proliferation of special purpose programming
languages to provide a complete development environment.

\tp{Smalltalk objects are "all levels of granularity"; UNIX files are large-scale; Haskell data structures small-scale; very big virtual machines; there is also the web / distributed file system?}

\emph{UNIX and Files}. Many programming languages and systems impose
structure at a ``fine granularity'': that of individual variables and
other data and code structures. Conversely, systems like UNIX and the
Web impose fewer restrictions on how programmers represent things. UNIX
insists only on a basic infrastructure of ``large objects''
\cite{KellOS}, delegating all fine-grained structure to client programs.
This scores many points for conceptual openness. \emph{Files} provide a
universal API for reading and writing byte streams, a low-level
construct containing so many degrees of freedom that it can support a
wide variety of formats and ecosystems. \emph{Processes} similarly
provide a thin abstraction over machine-level memory and processors.

Concepual integrity is necessarily sacrificed for such openness; while
``everything is a file'' gestures at integrity, in the vein of
Smalltalk's ``everything is an object'', exceptions proliferate.
Directories are special kinds of files with special operations, hardware
device files require special \texttt{ioctl} operations, and many
commands expect files containing newline separators. Additionally,
because client programs must supply their \emph{own} structure for
fine-grained data and code, they are given little in the way of mutual
compatibility. As a result, they tend to evolve into competing silos of
duplicated infrastructure \cite{KellOS,Mythical}.

\emph{The Web}. Web HTTP endpoints, meanwhile, have proven to be an even
more adaptable and viral abstraction than UNIX files. They operate at a
similar level of abstraction as files, but support richer content and
encompass internet-wide interactions between autonomous systems. In a
sense, HTTP GET and PUT have become the ``subroutine calls'' of an
internet-scale programming system. Perhaps the most salient thing about
the Web is that its usefulness came as such a surprise to everyone
involved in designing or competing with it. It is likely that, by
staying close to the existing practice of transferring files, the Web
gained a competitive edge over more ambitious and less familiar
hypertext projects like Xanadu \cite{TedNelson}.

The choice between compatibility and integrity correlates with the
personality traits of \emph{pragmatism} and \emph{idealism}. It is
pragmatic to accept the status quo of technology and make the best of
it. Conversely, idealists are willing to fight convention and risk
rejection in order to attain higher goals. We can wonder which came
first: the design decision or the personality trait? Do Lisp and Haskell
teach people to think more abstractly and coherently, or do they filter
for those with a pre-existing condition? Likewise, perhaps introverted
developers prefer the cloisters of Smalltalk or Lisp to the adventurous
``Wild West'' of the Web.

\hypertarget{dimension-composability}{%
\subsubsection{Dimension: composability}\label{dimension-composability}}

In short, \emph{you can get anywhere by putting together a number of
smaller steps.} There exist building blocks which span a range of useful
combinations.
\note{JE. LEGOs might be a more friendly example than Linear Algebra.
Such a property can be analogized to *linear independence* in mathematical vector spaces: a number of primitives (basis vectors) whose possible combinations span a meaningful space.}
Composability is, in a sense, key to the notion of ``programmability''
and every programmable system will have some level of composability
(e.g.~in the scripting language.)

\emph{UNIX} shell commands are a standard example of composability. The
base set of primitive commands can be augmented by programming command
executables in other languages. Given some primitives, one can ``pipe''
one's output to another's input (\texttt{\textbar{}}), sequence
(\texttt{;} or \texttt{\&\&}), select via conditions, and repeat with
loop constructs, enabling full imperative programming. Furthermore,
command compositions can be packaged into a named ``script'' which
follows the same interface as primitive commands, and named subprograms
within a script can also be defined.

In \emph{HyperCard}, the \emph{Authoring Environment} is
\emph{non}-composable for programming buttons: there is simply a set of
predefined behaviors to choose from. Full scriptability is available
only in the \emph{Programming Environment}.

The \emph{Haskell type system}, as well as that of other functional
programming languages, exhibits high composability. New types can be
defined in terms of existing ones in several ways. These include
records, discriminated unions, function types and recursive constructs
(e.g.~to define a \texttt{List} as either a \texttt{Nil} or a
combination of element plus other list.) The C programming language also
has some means of composing types that are analogous in some ways, such
as structs, unions, enums and indeed even function pointers. For every
type, there is also a corresponding ``pointer'' type. It lacks, however,
the recursive constructs permitted in Haskell types.

\note{*Web* Mashups in Web 2.0? Yahoo Pipes?}

\hypertarget{dimension-convenience}{%
\subsubsection{Dimension: convenience}\label{dimension-convenience}}

In short, \emph{you can get to X, Y or Z via one single step.} There are
ready-made solutions to specific problems, not necessarily generalizable
or composable. Convenience often manifests as ``canonical'' solutions
and utilities in the form of an expansive standard library.

Composability without convenience is a set of atoms or gears;
theoretically, anything one wants could be built out of them, but one
must do that work. This situation has been criticized as the \emph{Lisp
Curse} \cite{LispCurse}.

Composability \emph{with} convenience is a set of convenient specific
tools \emph{along with} enough components to construct new ones. The
specific tools themselves could be transparently composed of these
building blocks, but this is not essential. They save users the time and
effort it would take to ``roll their own'' solutions to common tasks.

For example, let us turn to a convenience factor of \emph{UNIX} shell
commands, having already discussed their composability above. Observe
that it would be possible, in principle, to pass all information to a
program via standard input. Yet in actual practice, for convenience,
there is a standard interface of \emph{command-line arguments} instead,
separate from anything the program takes through standard input. Most
programming systems similarly exhibit both composability and
convenience, providing templates, standard libraries, or otherwise
pre-packaged solutions, which can nevertheless be used programmatially
as part of larger operations.

\note{ex: something in the UI world? one click vs. long winded "principled" way of doing the thing? (macros? applescript?)}

\hypertarget{dimension-commonality}{%
\subsubsection{Dimension: commonality}\label{dimension-commonality}}

\note{JE This seems like data modelling issues that happen during application design, not programming system design.}

Humans can see Arrays, Strings, Dicts and Sets all have a ``size'', but
the software needs to be \emph{told} that they are the ``same''.
Commonality like this can be factored out into an explicit structure (a
``Collection'' class), analogous to database \emph{normalization}. This
way, an entity's size can be queried without reference to its particular
details: if \texttt{c} is declared to be a Collection, then one can
straightforwardly access \texttt{c.size}.

Alternatively, it can be left implicit. This is less upfront work, but
permits instances to \emph{diverge}, analogous to \emph{redundancy} in
databases. For example, Arrays and Strings might end up with ``length'',
while Dict and Set call it ``size''. This means that, to query the size
of an entity, it is necessary to perform a case split according to its
concrete type, solely to funnel the diverging paths back to the
commonality they represent:

\begin{verbatim}
if (entity is Array or String)  size := entity.length
else if (entity is Dict or Set) size := entity.size
\end{verbatim}

\joel{Web APIs e.g. onmousedown/onmouseup, imperative onmousemove instead of reified mouse pointer observable (this belongs more in a Factoring of Structure / Complexity dimension...)
   - tbh this is also a "machine legibility" issue; a human can recognise onmousemove and onmousedown as having something in common -- "mouse" -- but the computer just sees two non-equal strings as different as zQx6= and omlette.
   - onmousedown further makes the *mouse* part explicit, but the sub-device -- the button -- is passed as a numerical argument. ...
   - What really annoyed me, and seems most relevant, is that mouse buttons and keyboard keys the same in a very significant way -- they're binary-state buttons -- which means they ought to "implement the same interface", so the system will let me treat them the same insofar as they have commonalities like this. It should be trivial to rebind keyboard keys to the mouse buttons or vice versa, but this "poor factoring" obstructs this.
   - viz. OOP interfaces and abstraction, this factoring is forcing you to rely on irrelevant concrete details of the object. Instead of `if (isMouseButton) listenMouseButton(fn) else if (isKey) listenKey(fn)`, it should just be `listen(fn)`.}

\note{
EXAMPLES: interfaces/base classes; structural vs nominal typing
EXAMPLES: non-programming language world?
HyperCard - had shared backgrounds, which arose from the need of writing the help files.
}

\hypertarget{examples-flattening-and-factoring}{%
\subsubsection{Examples: flattening and
factoring}\label{examples-flattening-and-factoring}}

Data structures usually have several ``moving parts'' that can vary
independently. For example, a simple pair of ``vehicle type'' and
``color'' might have all combinations of (Car, Van, Train) and (Red,
Blue). In this \emph{factored} representation, we can programmatically
change the color directly: \texttt{pair.second\ =\ Red} or
\texttt{vehicle.colour\ =\ Red}.

In some contexts, such as class names, a system might only permit such
multi-dimensional structure as an \emph{exhaustive enumeration}: RedCar,
BlueCar, RedVan, BlueVan, RedTrain, BlueTrain, etc. The system sees a
flat list of atoms, even though a human can see the sub-structure
encoded in the string. In this world, we cannot simply ``change the
color to Red'' programmatically; we would need to case-split as follows:

\begin{verbatim}
if (type is BlueCar) type := RedCar
else if (type is BlueVan) type := RedVan
else if (type is BlueTrain) type := RedTrain
...
\end{verbatim}

The \emph{commonality} between RedCar, RedVan, BlueCar, and so on has
been \emph{flattened}. There is implicit structure here that remains
\emph{un-factored}, similar to how numbers can be expressed as singular
expressions (16) or as factor products (2,2,2,2). \emph{Factoring} this
commonality gives us the original design, where there is a pair of
values from different sets.

In \emph{relational databases}, there is an opposition between
\emph{normalization} and \emph{redundancy}. In order to fit multi-table
data into a \emph{flat} table structure, data needs to be duplicated
into redundant copies. When data is \emph{factored} into small tables as
much as possible, such that there is only one place each piece of data
``lives'', the database is in \emph{normal form} or \emph{normalized}.
Redundancy is useful for read-only processes, because there is no need
to join different tables together based on common keys. Writing,
however, becomes risky; in order to modify one thing, it must be
synchronized to the multiple places it is stored. This makes highly
normalized databases optimized for writes over reads.

\hypertarget{remark-the-end-of-history}{%
\subsubsection{Remark: the end of
history?}\label{remark-the-end-of-history}}

Today we live in a highly developed world of software technology. It is
estimated that 41,000 person years have been invested into Linux. We
describe software development technologies in terms of \emph{stacks} of
specialized tools, each of which might capitalize over 100 person-years
of development. Programming systems have become programming ecosystems:
not designed, but evolved. How can we noticeably improve programming in
the face of the overwhelming edifice of existing technology? There are
strong incentives to focus on localized incremental improvements that
don't cross the established boundaries.

The history of computing is one of cycles of evolution and revolution.
Successive cycles were dominated in turn by mainframes, minicomputers,
workstations, personal computers, and the Web. Each transition built a
whole new technology ecosystem replacing or on top of the previous. The
last revolution, the Web, was 25 years ago, with the result that many
people have never experienced a disruptive platform transition. Has
history stopped, or are we just stuck in a long cycle, with increasingly
pent-up pressures for change? If it is the latter, then incompatible
ideas now spurned may yet flourish.

\hypertarget{references-1}{%
\subsubsection{References}\label{references-1}}

\begin{itemize}
\tightlist
\item
  How to Design a Good API and Why it Matters \cite{APIdesign}
\end{itemize}

\DIFdelbegin %DIFDELCMD < \hypertarget{automation}{%
%DIFDELCMD < \subsection{Automation}\label{automation}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{complexity}{%
\subsection{Complexity}\label{complexity}}
\DIFaddend 

\DIFdelbegin %DIFDELCMD < \mybox{How far does the system remove the need to spell out implementation in minute detail?}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \mybox{How does the system structure complexity and what level of detail is required?}
\DIFaddend 

\DIFdelbegin \DIFdel{Ultimately, at the hardware level , computers are primitive calculating
machines. They require a full and exact specificiation of the
instructions to run.
}\DIFdelend \DIFaddbegin \DIFadd{There is a massive gap between the level of detail required by a
computer, which executes a sequence of low-level instructions, and the
human description of a program in higher-level terms. To bridge this
gap, a programming system needs to deal with the complexity inherent in
going from a high-level description to low-level instructions.
}

\DIFaddend Ever since the 1940s, programmers have envisioned that \DIFdelbegin \DIFdel{some form of }\DIFdelend ``automatic
programming'' will \DIFdelbegin \DIFdel{alleviate the need for
tediously specifying details at this level. While this level still
remains today, many aspects of the task of ``programming'' can and have
been }\emph{\DIFdel{automated.}}
%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{allow higher-level programming. This did not
necessarily mean full automation. In fact, the first ``automatic
programming'' systems referred to higher-level programming languages
with a compiler (or an interpreter) that expanded the high-level code
into detailed instructions.
}\DIFaddend 

\DIFdelbegin \DIFdel{Automation can take a number of forms.
Extracting common functionality
into
a library may be merely good use of }\emph{\DIFdel{factoring}} %DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{Most programming systems use }\emph{\DIFadd{factoring of complexity}} \DIFadd{and
encapsulate some of the details that need to be specified into
components that can be reused by the programmer. The details may be
encapsulated in a library, or filled in by a compiler or interpreter.
Such factoring may also be reflected in the conceptual structure of the
system }\DIFaddend (Section \ref{examples-flattening-and-factoring})\DIFdelbegin \DIFdel{, but to the user of the
library, this may appear as automation. In
high-level programming
languages, many details are also omitted; those are filled in by the
compiler. Finally, the program may also be executed by a more
sophisticated runtime that fills in details not specified explicitly,
such as when running an SQL query or using }\DIFdelend \DIFaddbegin \DIFadd{. However, a
system may also fully }\emph{\DIFadd{automate}} \DIFadd{some aspects of programming. In
those cases, }\DIFaddend a \DIFaddbegin \DIFadd{general-purpose algorithm solves a whole class of
problems, which then do not need to be coded explicitly. Think of
planning the execution of SQL queries, or of the inference engine
supporting a }\DIFaddend logic programming \DIFdelbegin \DIFdel{system
}\DIFdelend \DIFaddbegin \DIFadd{language }\DIFaddend like Prolog.

\hypertarget{remark-notations}{%
\subsubsection{Remark: notations}\label{remark-notations}}

Even \DIFdelbegin \DIFdel{with high-level of automation}\DIFdelend \DIFaddbegin \DIFadd{when working at a high level}\DIFaddend , programming involves manipulating
some program notation. In high-level functional or imperative
programming languages, the programmer writes code that typically has
clear operational meaning\DIFaddbegin \DIFadd{, even when some of the complexity is relegated
to a library implementation or a runtime}\DIFaddend . When using \DIFdelbegin \DIFdel{more declarative
programming }\DIFdelend \DIFaddbegin \DIFadd{declarative
programming systems }\DIFaddend like SQL, Prolog or Datalog, the meaning of a
program is still unambiguous, but it is not defined
operationally---there is a (more or less deterministic) inference engine
that solves the problem based on the provided description. Finally,
systems based on \emph{programming by example} step even further away
from having clear operational meaning---the program may be simply a
collection of sample inputs and outputs, from which a (\DIFdelbegin \DIFdel{typically }\DIFdelend \DIFaddbegin \DIFadd{possibly
}\DIFaddend non-deterministic) engine infers the concrete steps of execution.

\DIFdelbegin %DIFDELCMD < \hypertarget{dimension-degrees-of-automation}{%
%DIFDELCMD < \subsubsection{Dimension: degrees of
%DIFDELCMD < automation}\label{dimension-degrees-of-automation}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{dimension-factoring-of-complexity}{%
\subsubsection{Dimension: factoring of
complexity}\label{dimension-factoring-of-complexity}}
\DIFaddend 

\DIFdelbegin \DIFdel{There are many degrees of automation in programming systems, but the
basic mechanism is always the same---given }\DIFdelend \DIFaddbegin \DIFadd{The basic mechanism for dealing with complexity is }\emph{\DIFadd{factoring}} \DIFadd{it.
Given }\DIFaddend a program, \DIFdelbegin \DIFdel{some logic is
specified explicitlyand some is }\DIFdelend \DIFaddbegin \DIFadd{the more domain-specific aspects of the logic are
specified explicitly, whereas the more mundane and technical aspects of
the logic are }\DIFaddend left to a reusable component\DIFdelbegin \DIFdel{that can
do the rest. In the case of library reuse, the }\DIFdelend \DIFaddbegin \DIFadd{. Often, this }\DIFaddend reusable
component is just \DIFdelbegin \DIFdel{the library. In }\DIFdelend \DIFaddbegin \DIFadd{a library. Yet in }\DIFaddend the case of higher-level programming
languages, the reusable component may include a \DIFaddbegin \DIFadd{part of a language
runtime such as a }\DIFaddend memory allocator or a garbage collector. In case of
declarative languages or programming by example, the reusable component
is a general purpose inference engine.

\DIFdelbegin \DIFdel{Higher levels of automation require more complex }\emph{\DIFdel{reusable
components}} %DIFAUXCMD
\DIFdel{than lower levels. This is a difference between }\DIFdelend \DIFaddbegin \hypertarget{dimension-level-of-automation}{%
\subsubsection{Dimension: level of
automation}\label{dimension-level-of-automation}}

\DIFadd{Factoring of complexity shields the programmer from some details, but
those details still need to be explicitly programmed. Depending on the
customizability of the system, this programming may or may not be
accessible, but it is always there. For example, a function used in a
spreadsheet formula is implemented in the spreadsheet system.
}

\DIFadd{A programming system with higher }\DIFaddend \emph{level of automation} \DIFdelbegin \DIFdel{and }\emph{\DIFdel{factoring}}%DIFAUXCMD
\DIFdel{---producing systems with higher level of automation }\DIFdelend requires
more than simply \DIFdelbegin \DIFdel{extracting (factoring )
existing code into a reusable component. Instead, it requires doing more
work and introducing a
higher level of indirection between the program
and the
reusable component. }\DIFdelend \DIFaddbegin \DIFadd{factoring code into reusable components. It uses a
mechanism where some details of the operational meaning of a program are
never explicitly specified, but are inferred automatically by the
system. This is the approach of }\emph{\DIFadd{programming by example}} \DIFadd{and
}\emph{\DIFadd{machine learning}}\DIFadd{, where behaviour is specified through examples.
In some cases, deciding whether a feature is }\emph{\DIFadd{automation}} \DIFadd{or merely
}\emph{\DIFadd{factoring of complexity}} \DIFadd{is less clear: garbage collection can be
seen as either a simple case of automation, or a sophisticated case of
factoring complexity.
}\DIFaddend 

There is also an interesting (and perhaps inevitable) trade-off. The
higher the level of automation, the less explicit the operational
meaning of a program. This has a wide range of implications. Smaragdakis
\cite{NextGen} notes, for example, that this means the implementation
can significantly change the performance of a program.

\DIFaddbegin \hypertarget{example-domain-specific-languages}{%
\subsubsection{Example: domain-specific
languages}\label{example-domain-specific-languages}}

\DIFadd{Domain-specific languages \mbox{%DIFAUXCMD
\cite{DSLs} }\hspace{0pt}%DIFAUXCMD
provide an example of factoring of
complexity that does not involve automation. In this case, programming
is done at two levels. At the lower level, an (often more experienced)
programmer develops a domain-specific language, which lets a (typically
less experienced) programmer easily solve problems in a particular
domain: say, modelling of financial contracts, or specifying interactive
user interfaces.
}

\DIFadd{The domain-specific language provides primitives that can be composed,
but each primitive and each form of composition has explicitly
programmed and unambiguous operational meaning. The user of the
domain-specific language can think in the higher-level concepts it
provides, and this conceptual structure can be analysed using the
dimensions in Section\textasciitilde{}\ref{conceptual-structure}. As
long as these concepts are clear, the user does not need to be concerned
with the details of how exactly the resulting programs run.
}

\DIFaddend \hypertarget{example-programming-by-example}{%
\subsubsection{Example: programming by
example}\label{example-programming-by-example}}

An interesting case of automation is \emph{programming by example}
\cite{PBE}. In this case, the user does not provide even a declarative
specification of the program behavior, but instead specifies sample
inputs and outputs. A more or less sophisticated algorithm then attempts
to infer the relationship between the inputs and the outputs. This may,
for example, be done through program synthesis where an algorithm
composes a transformation using a (small) number of pre-defined
operations. Programming by example is often very accessible and has been
used in spreadsheet applications \cite{PBEExcel}.

\joel{ Sad to get rid of this, but we should find a better way to include Kell's fragmentation.
### Remark: fragmentation
An interesting issue is that reusable components that enable higher levels of automation are often specific to each system. This, arguably, limits what we can achieve as components that enable higher-levels of automation are increasingly complex to implement. For example, the resolution algorithm that is at the core of a Prolog system is typically tightly bound to the particular system and cannot be easily reused by another programming system.

As noted in \cite{KellOS,Mythical}, incompatible reusable components that exist for multiple systems also limit compositionality. One possible exception from the rule is the Z3 theorem prover, which is used as an implementation mechanism by multiple programming systems including Dafny and F*, as well as by numerous program verification tools.
}

\hypertarget{example-next-level-automation}{%
\subsubsection{Example: next-level
automation}\label{example-next-level-automation}}

Throughout history, programmers have always hoped for the next level of
``automatic programming''. As observed by Parnas \cite{Euphemism},
``automatic programming has always been a euphemism for programming in a
higher-level language than was then available to the programmer''.

We may speculate whether Deep Learning will enable the next step of
automation. However, this would not be different in principle from
existing developments. We can see any level of automation as using
\emph{artificial intelligence} methods. This is the case for declarative
languages or constraint-based languages---where the inference engine
implements a traditional AI method (GOFAI, i.e., Good Old Fashioned AI).

\joel{include a definition and discussion of "boilerplate" code!}
\note{Tomas: I removed references here, because I could not think of anything else to add here. I guess it makes sense to keep those optional..}

\DIFdelbegin %DIFDELCMD < \hypertarget{relations-1}{%
%DIFDELCMD < \subsubsection{Relations}\label{relations-1}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{relations-2}{%
\subsubsection{Relations}\label{relations-2}}
\DIFaddend 

\begin{itemize}
\tightlist
\item
  \DIFaddbegin \emph{\DIFadd{Conceptual structure}} \DIFadd{(Section~\ref{conceptual-structure}): In
  many cases, the factoring of complexity follows the conceptual
  structure of the programming system.
}\item
  \DIFaddend \emph{Flattening and factoring}
  (Section~\ref{examples-flattening-and-factoring}: One typically
  automates the thing at the lowest level in one's factoring (by making
  the lowest level a thing that exists outside of the program---in a
  system or a library)
\end{itemize}

\hypertarget{errors}{%
\subsection{Errors}\label{errors}}

\mybox{What does the system consider to be an *error*? How are they prevented and handled?}

A computer system is not aware of human intentions. There will always be
human mistakes that the system cannot recognize as errors. Despite this,
there are many that it \emph{can} recognize, and its design will
determine \emph{which} human mistakes can become detectable program
errors. This revolves around several questions: What can cause an error?
Which ones can be prevented from happening? How should the system react
to errors?

Following the standard literature on errors \cite{HumanError}, we
distinguish four kinds of errors: slips, lapses, mistakes and failures.
A \emph{slip} is an error caused by transient human attention failure,
such as a typo in the source code. A \emph{lapse} is similar but caused
by memory failure, such as an incorrectly remembered method name. A
\emph{mistake} is a logical error such as bad design of an algorithm.
Finally, a \emph{failure} is a system error caused by the system itself
that the programmer has no control over, e.g.~a hardware or a virtual
machine failure.

\hypertarget{dimensions-error-detection}{%
\subsubsection{Dimensions: error
detection}\label{dimensions-error-detection}}

Errors can be identified in any of the \emph{feedback loops} that the
system implements. This can be done either by a human or the system
itself, depending on the nature of the feedback loop.

Consider three examples. First, in live programming systems, the
programmer immediately sees the result of their code changes. Error
detection is done by a human and the system can assist this by
visualizing as many consequences of a code change as possible. Second,
in a system with a static checking feedback loop (such as syntax checks,
static type systems), potential errors are reported as the result of the
analysis. Third, errors can be detected when the developed software is
run, either when it is tested by the programmer (manually or through
automated testing) or when it is run by a user.

Error detection in different feedback loops is suitable for detecting
different kinds of errors. Many slips and lapses can be detected by the
static checking feedback loop, although this is not always the case. For
example, consider a ``compact'' \emph{expression geography} where small
changes in code may result in large changes of behaviour. This makes it
easier for slips and lapses to produce hard to detect errors. Mistakes
are easier to detect through a live feedback loop, but they can also be
partly detected by more advanced static checking.

\hypertarget{example-static-typing}{%
\subsubsection{Example: static typing}\label{example-static-typing}}

In statically typed programming languages like Haskell and Java, types
are used to capture some information about the intent of the programmer.
The type checker ensures code matches the lightweight specification
given using types. In such systems, types and implementation serve as
two descriptions of programmer's intent that need to align; what varies
is the extent to which types can capture intent and the way in which the
two are constructed; that is, which of the two comes first.

\hypertarget{examples-tdd-repl-and-live-coding}{%
\subsubsection{Examples: TDD, REPL and live
coding}\label{examples-tdd-repl-and-live-coding}}

Whereas static typing aims to detect errors without executing code,
approaches based on immediate feedback typically aim to execute (a
portion of) the code and let the programmer see the error immediately.
This can be done in a variety of ways.

In case of \emph{test-driven development}, tests play the role of
specification (much like types) against which the implementation is
checked. Such systems may provide more or less immediate feedback,
depending on when tests are executed (automatically in the background,
or manually). Systems equipped with a read-eval-print loop (REPL) let
programmers run code on-the-fly and inspect results. For successful
error detection, the results need to be easily observable: a printed
output is more helpful than a hidden change of system state. Finally, in
live coding systems, code is executed immediately and the programmer's
ability to recognize errors depends on the extent to which the system
state is observable. In live coded music, for example, you \emph{hear}
that your code is not what you wanted, providing an easy-to-use
immediate error detection mechanism.

\hypertarget{remark-eliminating-latent-errors}{%
\subsubsection{Remark: eliminating latent
errors}\label{remark-eliminating-latent-errors}}

A common aim of error detection is to prevent \emph{latent errors},
i.e.~errors that occured at some \emph{earlier} point during execution,
but only manifest themselves through an unexpected behaviour later on.
For example, we might dereference the wrong memory address and store a
junk value to a database; we will only find out upon accessing the
database. Latent errors can be prevented differently in different
feedback loops. In a live feedback loop, this can be done by visualizing
effects that would normally remain hidden. When running software, latent
errors can be prevented through a mechanism that detects errors as early
as possible (e.g.~initializing pointers to \texttt{null} and stopping if
they are dereferenced.)

\emph{Elm and time-travel debugging.} One notable mechanism for
identifying latent errors is the concept of \emph{time-travel debugging}
popularized by the Elm programming language. In time-travel debugging,
the programmer is able to step back through time and see what execution
steps were taken prior to a certain point. This makes it possible to
break execution when a latent error manifests, but then retrace the
execution back to the actual source of the error.

\hypertarget{dimension-error-response}{%
\subsubsection{Dimension: error
response}\label{dimension-error-response}}

When an error is detected, there are a number of typical ways in which
the system can respond. The following applies to systems that provide
some kind of error detection during execution.

\begin{itemize}
\tightlist
\item
  It may attempt to automatically recover from the error as best as
  possible. This may be feasible for simpler errors (slips and lapses),
  but also for certain mistakes (a mistake in an algorithm's concurrency
  logic may often be resolved by restarting the code.)
\item
  It may proceed as if the error did not happen. This can eliminate
  expensive checks, but may lead to latent errors later.
\item
  It may ask a human how to resolve the issue. This can be done
  interactively, by entering into a mode where the code can be
  corrected, or non-interactively by stopping the system.
\end{itemize}

Orthogonally to the above options, a system may also have a way to
recover from latent errors by tracing back through the execution in
order to find the root cause. It may also have a mechanism for undoing
all actions that occurred in the meantime, e.g.~through transactional
processing.

\emph{Interlisp and Do What I Mean (DWIM).} Interlisp's DWIM facility
attempts to automatically correct slips and lapses, especially
misspellings and unbalanced parentheses. When Interlisp encounters an
error, such as a reference to an undefined symbol, it invokes DWIM. In
this case, DWIM then searches for similarly named symbols frequently
used by the current user. If it finds one, it invokes the symbol
automatically, corrects the source code and notifies the user. In more
complex cases where DWIM cannot correct the error automatically, it
starts an interaction with the user and lets them correct it manually.

\DIFdelbegin %DIFDELCMD < \hypertarget{relations-2}{%
%DIFDELCMD < \subsubsection{Relations}\label{relations-2}}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \hypertarget{relations-3}{%
\subsubsection{Relations}\label{relations-3}}
\DIFaddend 

\begin{itemize}
\tightlist
\item
  \emph{Feedback loops}: Error detection always happens as part of an
  individual feedback loop. The feedback loops thus determine the
  structure at which error detection can happen.
  \note{- _Information loss_: Certain mechanism for error detection can only work if sufficient amount of information is available. For example, traveling debugger facility requires at least a form of execution log (but could also be easily implemented in a system based on bi-directional evaluation).}
\item
  \emph{Automation:} A semi-automatic error recovery system (such as
  DWIM) implements a form of automation. The concept of antifragile
  software \cite{Antifragile} is a more sophisticated example of error
  recovery through automation.
\item
  \emph{Expression geography:} In an expression geography where small
  changes in notation lead to valid but differently behaved programs, a
  slip or lapse is more likely to lead to an error that is difficult to
  detect through standard mechanisms.
\end{itemize}

\hypertarget{references-2}{%
\subsubsection{References}\label{references-2}}

The most common error handling mechanism in conventional programming
languages is exception handling. The modern form of exception handling
has been described by Goodenough~\cite{ExceptionHandling}; Ryder et
al.~\cite{SweImpact} documents the history and influences of Software
Engineering on exception handling. The concept of \emph{antifragile
software} \cite{Antifragile} goes further by suggesting that software
could improve in response to errors. Work on Chaos Engineering
\cite{ChaosMonkey} is a step in this direction.

Reason~\cite{HumanError} analyses errors in the context of human errors
and develops a classification of errors that we adopt. In the context of
computing, errors or \emph{miscomputation} has been analysed from a
philosophical perspective \cite{Miscomputation,MalfunctioningSW}.
Notably, attitudes and approaches to errors also differ for different
programming subcultures \cite{LivingWithErrors}.

\hypertarget{adoptability}{%
\subsection{Adoptability}\label{adoptability}}

\mybox{How does the system facilitate or obstruct adoption by both individuals and communities?}

We consider adoption by individuals as the dimension of
\emph{Learnability}, and adoption by communities as the dimension of
\emph{Sociability}.

\hypertarget{dimension-learnability}{%
\subsubsection{Dimension: learnability}\label{dimension-learnability}}

Mainstream software development technologies require substantial effort
to learn. Systems can be made easier to learn in several ways:

\begin{itemize}
\tightlist
\item
  Specializing to a specific application domain.
\item
  Specializing to simple small-scale needs.
\item
  Leveraging the background knowledge, skills, and terminologies of
  specific communities.
\item
  Supporting learning with staged levels of complexity and assistive
  development tools \cite{FullBrain}. Better \emph{Feedback Loops} can
  help (Section~\ref{interaction}).
\item
  Collapsing heterogeneous technology stacks into simpler unified
  systems. This relates to the dimensions under \emph{Conceptual
  Structure} (Section~\ref{conceptual-structure}).
\end{itemize}

FORTRAN was a breakthrough in programming because it specialized to
scientific computing and leveraged the background knowledge of
scientists about mathematical formulas. COBOL instead specialized to
business data processing and embraced the business community by
eschewing mathematics in favor of plain English.

LOGO was the first language explicitly designed for teaching children.
Later BASIC and Pascal were designed for teaching then-standard
programming concepts at the University level. BASIC and Pascal had
second careers on micropocessors in the 90's. These microprocessor
programming systems were notable for being complete solutions
integrating everything necessary, and so became home schools for a
generation of programmers. More recently languages like Racket, Pyret,
and Grace have supported learning by revealing progressive levels of
complexity in stages. Scratch returned to Logo's vision of teaching
children with a graphical programming environment emphasizing
playfulness rather than generality.

Some programming languages have consciously prioritized the programmer's
experience of learning and using them. Ruby calls itself \emph{a
programmer's best friend} by focusing on simplicity and elegance. Elm
targets the more specialized but still fairly broad domain of web
applications while focusing on simplicity and programmer-friendliness.
It forgoes capabilities that would lead to run-time crashes. It also
tries hard to make error messages clear and actionable.

If we look beyond programming languages \emph{per se}, we find
programmable systems with better learnability. The best example is
spreadsheets, which offer a specialized computing environment that is
simpler and more intuitive. The visual metaphor of a grid leverages
human perceptual skills. Moving all programming into declarative
formulas and attributes greatly simplifies both creation and
understanding. Research on Live Programming
\cite{Hancock2003,BretVictor} has sought to incorporate these benefits
into general purpose programming, but with limited success to date.

HyperCard and Flash were both programming systems that found widespread
adoption by non-experts. Like spreadsheets they had an organizing visual
metaphor (cards and timelines respectively). They both made it easy for
beginners to get started. Hypercard had layers of complexity intended to
facilitate gradual mastery.

Smalltalk and Lisp machines were complex but unified. After overcoming
the initial learning curve, their environments provided a complete
solution for building entire application systems of arbitrary complexity
without having to learn other technologies. Boxer \cite{BoxerDesign} is
notable for providing a general-purpose programming environment---albeit
for small-scale applications---along with an organizing visual metaphor
like that of spreadsheets.

\hypertarget{dimension-sociability}{%
\subsubsection{Dimension: sociability}\label{dimension-sociability}}

Over time, especially in the internet era, social issues have come to
dominate programming. Much programming technology is now developed by
open-source communities, and all programming technologies are now
embedded in social media communities of their users. \DIFdelbegin \DIFdel{The nature of these
communities often trumps purely technical and individual considerations
\mbox{%DIFAUXCMD
\cite{SocioPLT}}\hspace{0pt}%DIFAUXCMD
. Some of the specific concerns of sociability are}\DIFdelend \DIFaddbegin \DIFadd{Therefore,
technical decisions that impact socialibilty can be decisive
\mbox{%DIFAUXCMD
\cite{SocioPLT}}\hspace{0pt}%DIFAUXCMD
. These include}\DIFaddend :

\begin{itemize}
\tightlist
\item
  \DIFdelbegin \DIFdel{Easy }\DIFdelend \DIFaddbegin \DIFadd{Compatibility: easy }\DIFaddend integration into standard technology stacks,
  allowing incremental adoption, and also easy exit if needed. This
  dynamic was discussed in the classic essay \emph{Worse is Better}
  \cite{WIB} about how UNIX beat Lisp.
\item
  \DIFdelbegin \DIFdel{Backing by large corporations or widespread industry investments that
  ensures economic sustainability.
}%DIFDELCMD < \item
\item%DIFAUXCMD
%DIFDELCMD <   %%%
\DIFdel{An open-source community of volunteers investing their time, which has
  proven to be as viable as financial support}\DIFdelend \DIFaddbegin \DIFadd{Developing with an open source methodology reaps volunteer labor and
  fosters a user community of enthusiasts. The technical advantages of
  open source development were first popularized in the essay }\emph{\DIFadd{The
  Cathedral and the Bazaar}} \DIFadd{\mbox{%DIFAUXCMD
\cite{Cathedral}}\hspace{0pt}%DIFAUXCMD
, which observed that
  ``given enough eyeballs, all bugs are shallow''. Open source has
  become the standard for software development tools, even those
  developed within large corporations}\DIFaddend .
\item
  Easy sharing of code via package repositories or open exchanges. Prior
  to the open-source era, commercial marketplaces were important, like
  VBX components for VisualBasic. Sharing is impeded when languages \DIFdelbegin \DIFdel{have
  competing dialectsand libraries}\DIFdelend \DIFaddbegin \DIFadd{lack
  standard libraries, leading to competing dialects}\DIFaddend , like Scheme
  \cite{LispCurse}.
\item
  \DIFdelbegin \DIFdel{Friendly and helpful user communities on social media , for example
  Stack Overflow. Such communities have to
  some extent replaced the traditional role of }\DIFdelend \DIFaddbegin \DIFadd{Dedicated social media communities can be fostered by using them to
  provide technical support. Volunteer technical support, like volunteer
  code contributions, can multiply the impact of core developers. In
  some cases, social media like Stack Exchange has even come to replace
  }\DIFaddend documentation.
\end{itemize}

\DIFaddbegin \DIFadd{One could argue that socialibilty is not purely a }\emph{\DIFadd{technical}}
\DIFadd{dimension, as it includes aspects of product management. Rather, we
believe that sociability is a pervasive cross-cutting concern that
cannot be }\emph{\DIFadd{separated}} \DIFadd{from the technical.
}

\DIFaddend The tenor of the online community around a programming system can be its
most public attribute. Even before social media, Flash developed a
vibrant community of amateurs sharing code and tips. The Elm language
invested much effort in creating a welcoming community from the outset
\cite{WhatIsSuccess}. Attempts to reform older communities have
introduced Codes of Conduct, but not without controversy.

On the other hand, a cloistered community that turns its back on the
wider world can give its members strong feelings of belonging and
purpose. Examples are Smalltalk, Racket, Clojure, and Haskell. These
communities bear some resemblance to cults, with guru-like leaders, and
fierce group cohesion.

The economic sustainability of a programming system can be even more
important than strictly social and technical issues. Adopting a
technology is a costly investment in terms of time, money, and foregone
opportunities. Everyone feels safer investing in a technology backed by
large corporations that are not going away, or in technologies that have
such widespread adoption that they are guaranteed to persist. A vibrant
and mature open-source community backing a technology also makes it
safer.

Unfortunately, \DIFdelbegin \DIFdel{all of these issues of sociability create barriers to new
programming systems targeting non-experts, and indeed the entire
dimension of learnability}\DIFdelend \DIFaddbegin \DIFadd{sociability is often in conflict with learnability.
Compatibility leads to ever increasing historical baggage for new
learners to master}\DIFaddend . Large internet corporations have invested mainly in
technologies relevant to their \DIFaddbegin \DIFadd{expert staff and }\DIFaddend high-end needs.
Open-source communities have \DIFdelbegin \DIFdel{only }\DIFdelend \DIFaddbegin \DIFadd{mainly }\DIFaddend flourished around technologies for
expert programmers ``scratching their own itch''. While there has been a
flow of venture funding into ``no-code'' and ``low-code'' programming
systems, it is not clear how they can become economically and socially
sustainable. By and large, the internet era has seen the ascendancy of
expert programmers \DIFaddbegin \DIFadd{and the eclipsing of programming systems for ``the
rest of us''}\DIFaddend .

\bibliography{prog22}
\end{document}
